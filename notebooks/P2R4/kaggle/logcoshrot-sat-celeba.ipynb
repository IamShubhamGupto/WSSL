{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! git clone https://github.com/seshuad/IMagenet\n# ! ls 'IMagenet/tiny-imagenet-200/'","metadata":{"id":"KJwsGk0LTpKw","outputId":"31a51b41-c4fe-454d-e9fd-a50a1e402933","execution":{"iopub.status.busy":"2022-01-09T05:33:12.008149Z","iopub.execute_input":"2022-01-09T05:33:12.008579Z","iopub.status.idle":"2022-01-09T05:33:12.033433Z","shell.execute_reply.started":"2022-01-09T05:33:12.008453Z","shell.execute_reply":"2022-01-09T05:33:12.032782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -U tensorflow-addons","metadata":{"id":"qDokTqy3vDZS","outputId":"2aefd72c-955c-4eed-a7aa-8b699ab95525","execution":{"iopub.status.busy":"2022-01-09T05:33:12.034988Z","iopub.execute_input":"2022-01-09T05:33:12.035331Z","iopub.status.idle":"2022-01-09T05:33:12.039497Z","shell.execute_reply.started":"2022-01-09T05:33:12.035293Z","shell.execute_reply":"2022-01-09T05:33:12.038498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport scipy.ndimage as nd\nimport scipy.misc\nimport cv2\nimport numpy as np\nimport os\nimport glob\nimport gc\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom PIL import Image, ImageEnhance\nfrom random import randint\nimport pandas as pd\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, concatenate\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Input\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n# from google.colab.patches import cv2_imshow\nimport plotly.graph_objects as go\n%matplotlib inline","metadata":{"id":"Odj0CnQKVU_s","execution":{"iopub.status.busy":"2022-01-09T05:33:12.040955Z","iopub.execute_input":"2022-01-09T05:33:12.041259Z","iopub.status.idle":"2022-01-09T05:33:18.128295Z","shell.execute_reply.started":"2022-01-09T05:33:12.041224Z","shell.execute_reply":"2022-01-09T05:33:18.127566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random as rn\nnp.random.seed(4321)\nrn.seed(4321)\ntf.random.set_seed(4321)","metadata":{"id":"rJtLvQpI-vZh","execution":{"iopub.status.busy":"2022-01-09T05:33:18.130369Z","iopub.execute_input":"2022-01-09T05:33:18.130664Z","iopub.status.idle":"2022-01-09T05:33:18.137916Z","shell.execute_reply.started":"2022-01-09T05:33:18.130624Z","shell.execute_reply":"2022-01-09T05:33:18.136449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract test and training data from Tiny ImageNet DataSet","metadata":{"id":"licJlNBnT-wO"}},{"cell_type":"code","source":"# cnt = 0\n# for file in os.listdir(path):\n#     print(file)\n#     cnt += 1\n#     if(cnt==5):\n#         break\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:33:18.140017Z","iopub.execute_input":"2022-01-09T05:33:18.140355Z","iopub.status.idle":"2022-01-09T05:33:18.150702Z","shell.execute_reply.started":"2022-01-09T05:33:18.140313Z","shell.execute_reply":"2022-01-09T05:33:18.149748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotate_image():\n  return randint(0,3)\n\ndef sharpen_image():\n  return randint(0,3)","metadata":{"id":"MHhiosHItf-K","execution":{"iopub.status.busy":"2022-01-09T05:33:18.152445Z","iopub.execute_input":"2022-01-09T05:33:18.152752Z","iopub.status.idle":"2022-01-09T05:33:18.160700Z","shell.execute_reply.started":"2022-01-09T05:33:18.152717Z","shell.execute_reply":"2022-01-09T05:33:18.159853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IM_WIDTH = IM_HEIGHT = 64\nTRAIN_TEST_SPLIT = 0.8\ndataset_dict = {\n    'rotation_id': {\n        0: '0', \n        1: '90', \n        2: '180', \n        3: '270', \n    },\n    'saturation_id': {\n        0: '0.0',\n        1: '0.25',\n        2: '0.75',\n        3: '1.0'\n    }\n}\ndataset_dict['rotation_alias'] = dict((r, i) for i, r in dataset_dict['rotation_id'].items())\ndataset_dict['saturation_alias'] = dict((s, i) for i, s in dataset_dict['saturation_id'].items())","metadata":{"id":"I5h8c_KkpgcH","execution":{"iopub.status.busy":"2022-01-09T05:33:18.163131Z","iopub.execute_input":"2022-01-09T05:33:18.163638Z","iopub.status.idle":"2022-01-09T05:33:18.170630Z","shell.execute_reply.started":"2022-01-09T05:33:18.163601Z","shell.execute_reply":"2022-01-09T05:33:18.169823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(dataset, ext='JPEG'):\n    def generate_rotate_sharp():\n      res_rot = rotate_image()\n      res_sharp = sharpen_image()\n      return [res_rot, res_sharp]\n    \n    records = []\n    for filename in os.listdir(dataset):\n        info = generate_rotate_sharp()\n        records.append(info+[dataset+'/'+filename])\n        \n    df = pd.DataFrame(records)\n    df.columns = ['rotation_id', 'saturation_id', 'image']\n    df = df.dropna()\n    \n    return df\n\npath = '../input/celebahq-resized-256x256/celeba_hq_256'\ndf = prepare_dataset(path)\ndf.head()","metadata":{"id":"LKgkvtNRB7DC","outputId":"cc242f8c-0d94-45e6-cabb-72344a2d2afc","execution":{"iopub.status.busy":"2022-01-09T05:33:18.172035Z","iopub.execute_input":"2022-01-09T05:33:18.172384Z","iopub.status.idle":"2022-01-09T05:33:19.720680Z","shell.execute_reply.started":"2022-01-09T05:33:18.172349Z","shell.execute_reply":"2022-01-09T05:33:19.719927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(pd_series, key):\n    labels = pd_series.value_counts().index.tolist()\n    counts = pd_series.value_counts().values.tolist()\n    labels = list(map(lambda id: dataset_dict[key][id], labels))\n    # self.df['rotation_id'] = self.df['rotation'].map(lambda rotation: dataset_dict['rotation_alias'][rotation])\n    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)\n    fig = go.Figure(data=[pie_plot])\n    fig.update_layout(title_text='Distribution for %s' % pd_series.name)\n    \n    fig.show()","metadata":{"id":"nGNx7r3kMsyF","execution":{"iopub.status.busy":"2022-01-09T05:33:19.722220Z","iopub.execute_input":"2022-01-09T05:33:19.722482Z","iopub.status.idle":"2022-01-09T05:33:19.728336Z","shell.execute_reply.started":"2022-01-09T05:33:19.722447Z","shell.execute_reply":"2022-01-09T05:33:19.727412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(df['rotation_id'], 'rotation_id')","metadata":{"id":"rprgp1hRMtTr","outputId":"9f521675-6822-48c0-ad21-cc26266fef28","execution":{"iopub.status.busy":"2022-01-09T05:33:19.731869Z","iopub.execute_input":"2022-01-09T05:33:19.732163Z","iopub.status.idle":"2022-01-09T05:33:19.841606Z","shell.execute_reply.started":"2022-01-09T05:33:19.732126Z","shell.execute_reply":"2022-01-09T05:33:19.840759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(df['saturation_id'], 'saturation_id')","metadata":{"id":"sH0HiLDmMxBI","outputId":"b5bb8709-4ebb-4cb9-8fe5-af93a2096ff2","execution":{"iopub.status.busy":"2022-01-09T05:33:19.842980Z","iopub.execute_input":"2022-01-09T05:33:19.843251Z","iopub.status.idle":"2022-01-09T05:33:19.853948Z","shell.execute_reply.started":"2022-01-09T05:33:19.843215Z","shell.execute_reply":"2022-01-09T05:33:19.853265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_random_crop(image, crop_height, crop_width):\n\n    max_x = image.shape[1] - crop_width\n    max_y = image.shape[0] - crop_height\n\n    x = np.random.randint(0, max_x)\n    y = np.random.randint(0, max_y)\n\n    crop = image[y: y + crop_height, x: x + crop_width]\n\n    return crop\n\n# example_image = np.random.randint(0, 256, (1024, 1024, 3))\n# random_crop = get_random_crop(example_image, 64, 64)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:33:19.855757Z","iopub.execute_input":"2022-01-09T05:33:19.856306Z","iopub.status.idle":"2022-01-09T05:33:19.862859Z","shell.execute_reply.started":"2022-01-09T05:33:19.856268Z","shell.execute_reply":"2022-01-09T05:33:19.862239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImgDataGenerator():\n    \"\"\"\n    Data generator for the Tiny imagenet dataset. This class should be used when training our Keras multi-output model.\n    \"\"\"\n    def __init__(self, df):\n        self.df = df\n        \n    def generate_split_indexes(self):\n        self.df = self.df.sample(frac=1).reset_index(drop=True)\n        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n        train_val_idx = self.df.tail(train_up_to)\n        test_idx = self.df.head(len(self.df) - train_up_to)\n        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n        train_val_idx = train_val_idx.sample(frac=1).reset_index(drop=True)\n        train_idx, valid_idx = train_val_idx.tail(train_up_to), train_val_idx.head(len(train_val_idx) - train_up_to)\n        \n        return train_idx, valid_idx, test_idx\n    \n    \n    def preprocess_image(self, rotate: int, sharpen: int, img_path):\n        \"\"\"\n        Used to perform some minor preprocessing on the image before inputting into the network.\n        \"\"\"\n        im_cv = cv2.imread(img_path)\n        im = cv2.cvtColor(im_cv, cv2.COLOR_BGR2RGB)\n        # Crop the image to 224 x 224\n        im = get_random_crop(im, 224, 224)\n        \n        # Continue preprocessing\n        if rotate == 1:\n          im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n        elif rotate == 2:  \n          im = cv2.rotate(im, cv2.ROTATE_180)\n        elif rotate >= 3:\n          im = cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n        enhancer = ImageEnhance.Color(Image.fromarray(im))\n        saturation = 0.\n        if sharpen == 1:\n          saturation = 0.25\n          # out = unsharp_mask(im, amount=0.5)\n        elif sharpen == 2:  \n          saturation = 0.75\n          # out = unsharp_mask(im, amount = 1.5)\n        elif sharpen >= 3:\n          saturation = 1.\n          # out = unsharp_mask(im, amount = 2.5)\n        \n        out = np.array(enhancer.enhance(saturation))\n        # print(out.shape)\n        out = out / 255.0\n        \n        return out\n        \n    def generate_images(self, image_idx, is_training, batch_size=16):\n        \"\"\"\n        Used to generate a batch with images when training/testing/validating our Keras model.\n        \"\"\"\n        \n        # arrays to store our batched data\n        images, rotations, sharps = [], [], []\n        while True:\n            for idx in range(len(image_idx)):\n                row = image_idx.iloc[idx]\n                \n                rotation = row['rotation_id']\n                saturation = row['saturation_id']\n                img_path = row['image']\n                \n                im = self.preprocess_image(rotation, saturation, img_path)\n                \n                cat_rot = to_categorical(rotation, 4)\n                cat_sharp = to_categorical(saturation, 4)\n                rotations.append(cat_rot)\n                sharps.append(cat_sharp)\n                # print(\"rotation = \",rotation,\"cat_rot = \",cat_rot)\n                # print(\"saturation = \",saturation,\"cat_sharp = \",cat_sharp)\n                images.append(im)\n                \n                # yielding condition\n                if len(images) >= batch_size:\n                    yield np.array(images), [np.array(rotations), np.array(sharps)]\n                    images, rotations, sharps = [], [], []\n                    \n            if not is_training:\n                break\n                \ndata_generator = ImgDataGenerator(df)\ntrain_idx, valid_idx, test_idx = data_generator.generate_split_indexes()","metadata":{"id":"UG-RQzjSksEN","execution":{"iopub.status.busy":"2022-01-09T05:33:19.864580Z","iopub.execute_input":"2022-01-09T05:33:19.865137Z","iopub.status.idle":"2022-01-09T05:33:19.892548Z","shell.execute_reply.started":"2022-01-09T05:33:19.865082Z","shell.execute_reply":"2022-01-09T05:33:19.891806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_idx.shape)\nprint(valid_idx.shape)\nprint(test_idx.shape)","metadata":{"id":"i9MeYjcUSDfQ","outputId":"49cc6047-37e4-4dac-ab54-1d224d827c6e","execution":{"iopub.status.busy":"2022-01-09T05:33:19.894076Z","iopub.execute_input":"2022-01-09T05:33:19.894532Z","iopub.status.idle":"2022-01-09T05:33:19.900958Z","shell.execute_reply.started":"2022-01-09T05:33:19.894496Z","shell.execute_reply":"2022-01-09T05:33:19.900040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(test_idx.head())\n# print(type(test_idx))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:33:19.902699Z","iopub.execute_input":"2022-01-09T05:33:19.902978Z","iopub.status.idle":"2022-01-09T05:33:19.907811Z","shell.execute_reply.started":"2022-01-09T05:33:19.902944Z","shell.execute_reply":"2022-01-09T05:33:19.906870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:33:19.909352Z","iopub.execute_input":"2022-01-09T05:33:19.909756Z","iopub.status.idle":"2022-01-09T05:33:19.923249Z","shell.execute_reply.started":"2022-01-09T05:33:19.909720Z","shell.execute_reply":"2022-01-09T05:33:19.922607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = 0\nif DEBUG:\n    fig = plt.figure(figsize=(20., 20.))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(4, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n    data_gen = data_generator.generate_images(test_idx, is_training=False, batch_size=8)\n  # images = data_gen[0]\n    for i,data in enumerate(data_gen):\n        images, outputs = data\n        print(len(images))\n#         for j, image in enumerate(images):\n#             image *= 255.0\n#             print(\"rotation \",outputs[0][j])\n#             print(\"saturation \",outputs[1][j])\n#             grid.imshow(image)\n            \n        for ax, im in zip(grid, images):\n            # Iterating over the grid returns the Axes.\n            ax.imshow(im)\n\n        plt.show()\n        break","metadata":{"id":"RnvdMQAXcKhD","execution":{"iopub.status.busy":"2022-01-09T05:33:19.924581Z","iopub.execute_input":"2022-01-09T05:33:19.924832Z","iopub.status.idle":"2022-01-09T05:33:19.931305Z","shell.execute_reply.started":"2022-01-09T05:33:19.924800Z","shell.execute_reply":"2022-01-09T05:33:19.930409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel = (3,3)\npool = (2,2)\nupstride = (2,2)\nactivation = 'relu'\nclass inpaintingModel:\n  def build_encoder(self, inputs):\n    # inputs = keras.layers.Input(input_size)\n    conv1, pool1 = self.__ConvBlock(64, kernel, pool, activation, 'same', inputs) \n    conv2, pool2 = self.__ConvBlock(128, kernel, pool, activation, 'same', pool1)\n    conv3, pool3 = self.__ConvBlock(256, kernel, pool, activation, 'same', pool2) \n    conv4, pool4 = self.__ConvBlock(512, kernel, pool, activation, 'same', pool3) \n    conv5, pool5 = self.__ConvBlock(1024, kernel, pool, activation, 'same', pool4)\n\n    return conv1, conv2, conv3, conv4, conv5, pool5\n\n  def build_decoder(self, conv1, conv2, conv3, conv4, conv5, pool_layer):\n    conv6, up7 = self.__UpConvBlock(2048, 1024, kernel, pool, upstride, activation, 'same', pool_layer, conv5)\n    conv7, up8 = self.__UpConvBlock(1024, 512, kernel, pool, upstride, activation, 'same', up7, conv4)\n    conv8, up9 = self.__UpConvBlock(512, 256, kernel, pool, upstride, activation, 'same', up8, conv3)\n    conv9, up10 = self.__UpConvBlock(256, 128, kernel, pool, upstride, activation, 'same', up9, conv2)\n    conv10, up11 = self.__UpConvBlock(128, 64, kernel, pool, upstride, activation, 'same', up10, conv1)\n\n    conv11 = self.__ConvBlock(32, kernel, pool, activation, 'same', up11, False)\n    \n    outputs = keras.layers.Conv2D(3, kernel, activation='sigmoid', padding='same')(conv11)\n\n    return outputs\n  '''\n  Build UNET like model for image inpaining task.\n  '''\n  def prepare_model(self, input_size=(224,224,3)):\n    inputs = keras.layers.Input(input_size)\n    conv1, conv2, conv3, conv4, conv5, pool_layer = self.build_encoder(inputs)\n    outputs = self.build_decoder(conv1, conv2, conv3, conv4, conv5, pool_layer)\n    # conv1, pool1 = self.__ConvBlock(64, kernel, pool, activation, 'same', inputs) \n    # conv2, pool2 = self.__ConvBlock(128, kernel, pool, activation, 'same', pool1)\n    # conv3, pool3 = self.__ConvBlock(256, kernel, pool, activation, 'same', pool2) \n    # conv4, pool4 = self.__ConvBlock(512, kernel, pool, activation, 'same', pool3) \n    # conv5, pool5 = self.__ConvBlock(1024, kernel, pool, activation, 'same', pool4)\n     \n\n    # conv6, up7 = self.__UpConvBlock(2048, 1024, kernel, pool, upstride, activation, 'same', pool5, conv5)\n    # conv7, up8 = self.__UpConvBlock(1024, 512, kernel, pool, upstride, activation, 'same', up7, conv4)\n    # conv8, up9 = self.__UpConvBlock(512, 256, kernel, pool, upstride, activation, 'same', up8, conv3)\n    # conv9, up10 = self.__UpConvBlock(256, 128, kernel, pool, upstride, activation, 'same', up9, conv2)\n    # conv10, up11 = self.__UpConvBlock(128, 64, kernel, pool, upstride, activation, 'same', up10, conv1)\n\n    # conv11 = self.__ConvBlock(64, kernel, pool, activation, 'same', up11, False)\n    \n    # outputs = keras.layers.Conv2D(3, kernel, activation='sigmoid', padding='same')(conv11)\n    # inpur\n    return keras.models.Model(inputs=[inputs], outputs=[outputs])  \n\n  def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n    if pool_layer:\n      pool = keras.layers.MaxPooling2D(pool_size)(conv)\n      return conv, pool\n    else:\n      return conv\n\n  def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n    up = keras.layers.Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)\n    up = keras.layers.concatenate([up, shared_layer], axis=3)\n\n    return conv, up","metadata":{"id":"mTjnopo0T56m","execution":{"iopub.status.busy":"2022-01-09T05:33:19.932841Z","iopub.execute_input":"2022-01-09T05:33:19.933150Z","iopub.status.idle":"2022-01-09T05:33:19.954814Z","shell.execute_reply.started":"2022-01-09T05:33:19.933118Z","shell.execute_reply":"2022-01-09T05:33:19.954131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class pretextModel:\n  def assemble_head_branch(self,  pool_layer, name):\n    x = Flatten()(pool_layer)\n    x = Dense(512)(x)\n    # x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n        \n    # x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    # x = Dense(2048, \n    #           kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n    #           bias_regularizer=tf.keras.regularizers.l2(1e-4),\n    #           activity_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n    x = Dense(512)(x)\n    # x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    # x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    x = Dense(4)(x)\n    x = Activation(\"softmax\", name=name)(x)\n    return x\n\n  def assemble_pretext_model(self):\n    inputs = keras.layers.Input((224,224,3))\n    conv1, conv2, conv3, conv4, conv5, pool_layer = inpaintingModel().build_encoder(inputs) \n    rotation_branch = self.assemble_head_branch(pool_layer, \"rotation_output\")\n    saturation_branch = self.assemble_head_branch(pool_layer, \"saturation_output\")\n    model = Model(inputs=inputs,\n                  outputs = [rotation_branch, saturation_branch],\n                  name=\"pretext_net\")\n    return model","metadata":{"id":"2_Sw1JD55buR","execution":{"iopub.status.busy":"2022-01-09T05:33:19.957092Z","iopub.execute_input":"2022-01-09T05:33:19.957702Z","iopub.status.idle":"2022-01-09T05:33:19.967425Z","shell.execute_reply.started":"2022-01-09T05:33:19.957665Z","shell.execute_reply":"2022-01-09T05:33:19.966666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nkeras.backend.clear_session()","metadata":{"id":"nYur1hQvJQxl","execution":{"iopub.status.busy":"2022-01-09T05:33:19.968422Z","iopub.execute_input":"2022-01-09T05:33:19.969183Z","iopub.status.idle":"2022-01-09T05:33:19.992135Z","shell.execute_reply.started":"2022-01-09T05:33:19.969146Z","shell.execute_reply":"2022-01-09T05:33:19.991444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model = pretextModel().assemble_pretext_model()","metadata":{"id":"lYbHItKN4FwN","execution":{"iopub.status.busy":"2021-12-12T03:20:00.041819Z","iopub.execute_input":"2021-12-12T03:20:00.042059Z","iopub.status.idle":"2021-12-12T03:20:02.516822Z","shell.execute_reply.started":"2021-12-12T03:20:00.042027Z","shell.execute_reply":"2021-12-12T03:20:02.516081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(p_model, show_shapes=True, dpi=76, to_file='p_model_v1.png')","metadata":{"id":"in33Y6VFtvd8","outputId":"caf5df4d-3476-4856-e29e-196dba03a2ae","scrolled":true,"execution":{"iopub.status.busy":"2021-12-12T03:20:02.518053Z","iopub.execute_input":"2021-12-12T03:20:02.518485Z","iopub.status.idle":"2021-12-12T03:20:03.456622Z","shell.execute_reply.started":"2021-12-12T03:20:02.518448Z","shell.execute_reply":"2021-12-12T03:20:03.453606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model.summary()","metadata":{"id":"xqSMYuKnQuQW","outputId":"676139fd-a1a8-422c-d823-12e5d865d539","scrolled":true,"execution":{"iopub.status.busy":"2021-12-12T03:20:03.457911Z","iopub.execute_input":"2021-12-12T03:20:03.458481Z","iopub.status.idle":"2021-12-12T03:20:03.482317Z","shell.execute_reply.started":"2021-12-12T03:20:03.458451Z","shell.execute_reply":"2021-12-12T03:20:03.481625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\nepochs = 40\nopt = Adam(learning_rate=init_lr, amsgrad=False)\np_model.compile(optimizer=opt, \n              loss={\n                  'rotation_output': 'categorical_crossentropy', \n                  'saturation_output': 'categorical_crossentropy'},\n              \n              loss_weights={\n                  'rotation_output': 0.3, \n                  'saturation_output': 0.7},\n              metrics={\n                  'rotation_output': 'accuracy',\n                  'saturation_output': 'accuracy'})","metadata":{"id":"LyaXTzFgpWL7","execution":{"iopub.status.busy":"2021-12-12T03:20:03.483565Z","iopub.execute_input":"2021-12-12T03:20:03.483808Z","iopub.status.idle":"2021-12-12T03:20:03.503326Z","shell.execute_reply.started":"2021-12-12T03:20:03.483775Z","shell.execute_reply":"2021-12-12T03:20:03.502415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"./p_model_checkpoint\", monitor='val_loss')\nbatch_size = 64\ntrain_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\nvalid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=batch_size)\ncallbacks = [early_stopping, checkpoint]\nhistory = p_model.fit(train_gen,\n                    steps_per_epoch=len(train_idx)//batch_size,\n                    epochs=epochs,\n#                     callbacks=callbacks,\n                    # class_weight=dict(\n                    #     rotation_output = rots_dict,\n                    #     saturation_output = sharps_dict\n                    # ), \n                    # use_multiprocessing=True,\n                    validation_data=valid_gen,\n                    validation_steps=len(valid_idx)//batch_size)","metadata":{"id":"j0PS7XzZqF8Y","outputId":"c2933650-6311-4316-833d-3f6e58ad3a82","execution":{"iopub.status.busy":"2021-12-12T03:20:03.505956Z","iopub.execute_input":"2021-12-12T03:20:03.506189Z","iopub.status.idle":"2021-12-12T04:50:27.393935Z","shell.execute_reply.started":"2021-12-12T03:20:03.506145Z","shell.execute_reply":"2021-12-12T04:50:27.392908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# c","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:50:27.395746Z","iopub.execute_input":"2021-12-12T04:50:27.39603Z","iopub.status.idle":"2021-12-12T04:50:27.400275Z","shell.execute_reply.started":"2021-12-12T04:50:27.395994Z","shell.execute_reply":"2021-12-12T04:50:27.399309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(metric):\n  plt.clf()\n  fig = go.Figure(layout_yaxis_range=[0,2])\n  fig.add_trace(go.Scatter(\n                      y=history.history[metric],\n                      name='Train'))\n  fig.add_trace(go.Scatter(\n                      y=history.history['val_'+metric],\n                      name='Valid'))\n  fig.update_layout(height=500, \n                    width=700,\n                    title=metric,\n                    xaxis_title='Epoch',\n                    yaxis_title='Accuracy/Loss')\n  fig.show()\n\nmetrics = ['rotation_output_accuracy', 'rotation_output_loss', 'saturation_output_accuracy', 'saturation_output_loss', 'loss']\nfor i in metrics:\n  plot_metric(i)","metadata":{"id":"hW_E0Uik9LLf","outputId":"3144d6cf-ff11-4592-a0dd-7b6ee2e79766","execution":{"iopub.status.busy":"2021-12-12T04:50:27.401904Z","iopub.execute_input":"2021-12-12T04:50:27.402539Z","iopub.status.idle":"2021-12-12T04:50:27.497783Z","shell.execute_reply.started":"2021-12-12T04:50:27.402501Z","shell.execute_reply":"2021-12-12T04:50:27.497055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# p_model.save('rot-sat-30_70.h5')\nfrom tensorflow.keras.models import load_model\np_model = load_model('../input/pretexttaskmodel/rot-sat-30_70/rot-sat-30_70.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:33:39.720221Z","iopub.execute_input":"2022-01-09T05:33:39.720862Z","iopub.status.idle":"2022-01-09T05:33:54.889778Z","shell.execute_reply.started":"2022-01-09T05:33:39.720822Z","shell.execute_reply":"2022-01-09T05:33:54.889047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch_size = 64 # 256\ntest_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nrotation_pred, saturation_pred= p_model.predict(test_generator, \n                                                           steps=len(test_idx)//test_batch_size)","metadata":{"id":"NzxfWygGC8tE","execution":{"iopub.status.busy":"2021-12-12T04:50:37.849073Z","iopub.execute_input":"2021-12-12T04:50:37.849533Z","iopub.status.idle":"2021-12-12T04:51:38.957994Z","shell.execute_reply.started":"2021-12-12T04:50:37.849495Z","shell.execute_reply":"2021-12-12T04:51:38.957226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nsamples = 0\nimages, rotation_true, saturation_true = [], [], []\nfor test_batch in test_generator:\n    image = test_batch[0]\n    labels = test_batch[1]\n    \n    images.extend(image)\n    rotation_true.extend(labels[0])\n    saturation_true.extend(labels[1])\n    \nrotation_true = np.array(rotation_true)\nsaturation_true = np.array(saturation_true)\nrotation_true, saturation_true = rotation_true.argmax(axis=-1), saturation_true.argmax(axis=-1)\nrotation_pred, saturation_pred = rotation_pred.argmax(axis=-1), saturation_pred.argmax(axis=-1)\n","metadata":{"id":"E0IlUa85DFJH","execution":{"iopub.status.busy":"2021-12-12T04:51:38.961269Z","iopub.execute_input":"2021-12-12T04:51:38.961486Z","iopub.status.idle":"2021-12-12T04:52:00.048355Z","shell.execute_reply.started":"2021-12-12T04:51:38.961461Z","shell.execute_reply":"2021-12-12T04:52:00.047621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr_rotation = classification_report(rotation_true, rotation_pred, target_names=dataset_dict['rotation_alias'].keys())\nprint(cr_rotation)","metadata":{"id":"nF35bZIODfm6","outputId":"f032439c-e339-44ef-8dd2-a752d9bb85eb","execution":{"iopub.status.busy":"2021-12-12T04:52:00.049832Z","iopub.execute_input":"2021-12-12T04:52:00.0501Z","iopub.status.idle":"2021-12-12T04:52:00.070575Z","shell.execute_reply.started":"2021-12-12T04:52:00.050064Z","shell.execute_reply":"2021-12-12T04:52:00.069852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr_saturation = classification_report(saturation_true, saturation_pred, target_names=dataset_dict['saturation_alias'].keys())\nprint(cr_saturation)","metadata":{"id":"jPGhCed7DrxU","outputId":"878634f0-cc36-4ae5-b52d-ace7c75d654e","execution":{"iopub.status.busy":"2021-12-12T04:52:00.07159Z","iopub.execute_input":"2021-12-12T04:52:00.071776Z","iopub.status.idle":"2021-12-12T04:52:00.107785Z","shell.execute_reply.started":"2021-12-12T04:52:00.071754Z","shell.execute_reply":"2021-12-12T04:52:00.107069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask_path = '../input/quick-draw-irregular-mask-dataset/qd_imd'\nmask_path = '../input/qd-imd-30-50/qd_imd'","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:34:56.490862Z","iopub.execute_input":"2022-01-09T05:34:56.491251Z","iopub.status.idle":"2022-01-09T05:34:56.494498Z","shell.execute_reply.started":"2022-01-09T05:34:56.491215Z","shell.execute_reply":"2022-01-09T05:34:56.493852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.\nclass createAugment(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, mask_path, is_training, batch_size=128, dim=(224, 224), n_channels=3, shuffle=True):\n        'Initialization'\n        self.batch_size = batch_size \n        self.df = df\n        self.mask_path = mask_path\n        self.is_training = is_training\n        self.dim = dim\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.df) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Generate data\n        return self.__data_generation(indexes)\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, idxs):\n        # X_batch is a matrix of masked images used as input\n        X_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Masked image\n        # y_batch is a matrix of original images used for computing error from reconstructed image\n        y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Original image\n\n        ## Iterate through random indexes\n        for i, idx in enumerate(idxs):\n            # image_copy = self.X[idx].copy()\n#             print(self.df.iloc[idx]['image'])\n            image_copy = cv2.imread(self.df.iloc[idx]['image'])\n            image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n            # Crop the image to 224 x 224\n            image_copy = get_random_crop(image_copy, 224, 224)\n\n            ## Get mask associated to that image\n            masked_image = self.__createMask(image_copy)\n\n            X_batch[i,] = masked_image/255\n            y_batch[i] = image_copy/255\n\n        return X_batch, y_batch\n\n    def __createMask(self, img):\n        directory = \"Unknown\"\n        mask_no = -1\n        if(self.is_training):\n            directory = 'train'\n            mask_no = np.random.randint(0,14991-1)\n        else:\n            directory = 'test'\n            mask_no = np.random.randint(0,3122-1)\n            \n        # Pad the mask_no\n        mask_no = str(mask_no).zfill(5)\n        \n        img_path = self.mask_path+'/'+ directory + '/' + mask_no + '_'+ directory + '.png'\n        mask = cv2.imread(img_path)\n#         mask = cv2.resize(mask, (256,256))\n#         mask = get_random_crop(mask, 224, 224)\n        \n#         thresh = 127\n#         mask = cv2.threshold(mask, thresh, 255, cv2.THRESH_BINARY)[1]\n#         print(type(img), type(mask))\n#         print(img.shape, mask.shape)\n        masked_image = cv2.bitwise_and(img, mask)\n\n        return masked_image","metadata":{"id":"uNUAcv_r_2Vj","execution":{"iopub.status.busy":"2022-01-09T05:35:18.839240Z","iopub.execute_input":"2022-01-09T05:35:18.840283Z","iopub.status.idle":"2022-01-09T05:35:18.857072Z","shell.execute_reply.started":"2022-01-09T05:35:18.840234Z","shell.execute_reply":"2022-01-09T05:35:18.856337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train, x_test, y_test = get_data(get_id_dictionary())","metadata":{"id":"YB-acxaFYCfH","outputId":"c97c563e-a226-4c1e-aed9-0a7eab1994bc","execution":{"iopub.status.busy":"2022-01-09T05:35:18.859351Z","iopub.execute_input":"2022-01-09T05:35:18.859892Z","iopub.status.idle":"2022-01-09T05:35:18.870621Z","shell.execute_reply.started":"2022-01-09T05:35:18.859851Z","shell.execute_reply":"2022-01-09T05:35:18.869870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Prepare training and testing mask-image pair generator\nd_train_gen = createAugment(train_idx, mask_path, is_training = 1, batch_size=64)\nd_test_gen = createAugment(test_idx, mask_path, is_training = 0, shuffle=False, batch_size=64)","metadata":{"id":"_FOZveBp_5Bn","execution":{"iopub.status.busy":"2022-01-09T05:35:18.872734Z","iopub.execute_input":"2022-01-09T05:35:18.873534Z","iopub.status.idle":"2022-01-09T05:35:18.880740Z","shell.execute_reply.started":"2022-01-09T05:35:18.873496Z","shell.execute_reply":"2022-01-09T05:35:18.880035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"id":"izuhVt9CZQsq","execution":{"iopub.status.busy":"2022-01-09T05:35:18.882317Z","iopub.execute_input":"2022-01-09T05:35:18.882666Z","iopub.status.idle":"2022-01-09T05:35:18.889270Z","shell.execute_reply.started":"2022-01-09T05:35:18.882614Z","shell.execute_reply":"2022-01-09T05:35:18.888530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Examples\nsample_idx = 90 ## Change this to see different batches\n\nsample_masks, sample_labels = d_train_gen[sample_idx]\nsample_images = [None]*(len(sample_masks)+len(sample_labels))\nsample_images[::2] = sample_labels\nsample_images[1::2] = sample_masks\n\nfig = plt.figure(figsize=(16., 8.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(4, 8),  # creates 2x2 grid of axes\n                 axes_pad=0.3,  # pad between axes in inch.\n                 )\n\nfor ax, image in zip(grid, sample_images):\n    ax.imshow(image)\n\nplt.show()","metadata":{"id":"5kK7AR03AEL4","outputId":"e96c8e49-f5c3-44df-aefd-a95beede04cb","execution":{"iopub.status.busy":"2022-01-09T05:35:18.891452Z","iopub.execute_input":"2022-01-09T05:35:18.891731Z","iopub.status.idle":"2022-01-09T05:35:24.352815Z","shell.execute_reply.started":"2022-01-09T05:35:18.891693Z","shell.execute_reply":"2022-01-09T05:35:24.352131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For more information into formulation: https://www.youtube.com/watch?v=AZr64OxshLo\n## Metric\nfrom sklearn.metrics import jaccard_score\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.backend.flatten(y_true)\n    y_pred_f = keras.backend.flatten(y_pred)\n    intersection = keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection) / (keras.backend.sum(y_true_f + y_pred_f))\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef ssim_loss(y_true, y_pred):\n    return 1 - SSIM(y_true, y_pred, multichannel=True)\n\ndef ssim_coef(y_true, y_pred):\n    return 1 - SSIM(y_true, y_pred, multichannel=True)\n\ndef SSIMLoss(y_true, y_pred):\n  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\ndef custom_loss(y_true, y_pred):\n    alpha = 0.84\n    loss_ssim = SSIMLoss(y_true, y_pred)\n    \n#     jaccard_dist = jaccard_score(y_true.flatten(), y_pred.flatten())\n#     jaccard_dist = jaccard_distance(y_true, y_pred)\n    logcosh = tf.keras.losses.logcosh(y_true, y_pred)\n#     loss_mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n    return loss_ssim #(1-alpha)*loss_ssim + alpha*logcosh\ndef logcosh(y_true, y_pred):\n    return tf.keras.losses.logcosh(y_true, y_pred)","metadata":{"id":"SJdz5Sf1_jYU","execution":{"iopub.status.busy":"2022-01-09T05:35:24.353829Z","iopub.execute_input":"2022-01-09T05:35:24.354046Z","iopub.status.idle":"2022-01-09T05:35:24.365877Z","shell.execute_reply.started":"2022-01-09T05:35:24.354012Z","shell.execute_reply":"2022-01-09T05:35:24.365153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\nd_model = inpaintingModel().prepare_model()\ndepth = 16\ninit_lr = 1e-4\nopt = Adam(learning_rate=init_lr, amsgrad=False)\n  # d_model.layers[:depth]:\n  # print(i)\n  # layer.set_weights(p_model.layers)\n  # d_model.trainable_weights[i].assign(p_model.trainable_weights[i])\nfor i in range(depth):\n    d_model.layers[i].set_weights(p_model.layers[i].get_weights())\n    d_model.layers[i].trainable = False\nd_model.compile(optimizer=opt, loss= [logcosh], metrics=[dice_coef], \n#                 run_eagerly = True\n               )\n\nkeras.utils.plot_model(d_model, show_shapes=True, dpi=76, to_file='d_model_v1.png')","metadata":{"id":"oiRBX-YI0fs9","outputId":"039e281d-2dfd-4ede-b183-2442af96d2d1","scrolled":true,"execution":{"iopub.status.busy":"2022-01-09T05:35:24.368045Z","iopub.execute_input":"2022-01-09T05:35:24.368441Z","iopub.status.idle":"2022-01-09T05:35:26.126472Z","shell.execute_reply.started":"2022-01-09T05:35:24.368403Z","shell.execute_reply":"2022-01-09T05:35:26.125764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_model.summary()","metadata":{"id":"Te29ATXfZzGA","outputId":"0e0758a9-91f2-47a6-e5b1-1bade3c6939e","scrolled":true,"execution":{"iopub.status.busy":"2022-01-09T05:35:26.127825Z","iopub.execute_input":"2022-01-09T05:35:26.128203Z","iopub.status.idle":"2022-01-09T05:35:26.134767Z","shell.execute_reply.started":"2022-01-09T05:35:26.128166Z","shell.execute_reply":"2022-01-09T05:35:26.134043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_model.layers[5].get_weights()","metadata":{"id":"wJwp4NDXZ-_E","execution":{"iopub.status.busy":"2022-01-09T05:35:26.136075Z","iopub.execute_input":"2022-01-09T05:35:26.136777Z","iopub.status.idle":"2022-01-09T05:35:26.144096Z","shell.execute_reply.started":"2022-01-09T05:35:26.136740Z","shell.execute_reply":"2022-01-09T05:35:26.142973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trying again\n## IT WORKS !!!","metadata":{"id":"dKYPHN--ezgP"}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"./d_model_checkpoint\", monitor='dice_coef')\nbatch_size = 64\n# train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n# valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\ncallbacks = [early_stopping, checkpoint]\nd_history = d_model.fit(d_train_gen,\n                    # steps_per_epoch=len(d_train_gen)//batch_size,\n                    epochs=20,\n#                     callbacks=callbacks,\n                    # validation_split = 0.25\n                    validation_data=d_test_gen\n                    # validation_steps = len(d_test_gen)//batch_size\n                    )\n                    # class_weight=dict(\n                    #     rotation_output = rots_dict,\n                    #     saturation_output = sharps_dict\n                    # ), \n                    # use_multiprocessing=True,\n                    # validation_data=valid_gen,\n                    # validation_steps=len(valid_idx)//valid_batch_size)","metadata":{"id":"XCeHYnsOA5sW","outputId":"ef706b87-44bf-429f-b0dc-d1ca617b03be","execution":{"iopub.status.busy":"2022-01-09T05:35:26.145750Z","iopub.execute_input":"2022-01-09T05:35:26.146019Z","iopub.status.idle":"2022-01-09T07:24:42.219163Z","shell.execute_reply.started":"2022-01-09T05:35:26.145971Z","shell.execute_reply":"2022-01-09T07:24:42.218411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.metrics import structural_similarity as SSIM\nfrom skimage.metrics import peak_signal_noise_ratio as PSNR","metadata":{"id":"yBp4NwXNcnE9","execution":{"iopub.status.busy":"2022-01-09T07:24:42.220969Z","iopub.execute_input":"2022-01-09T07:24:42.221272Z","iopub.status.idle":"2022-01-09T07:24:42.370204Z","shell.execute_reply.started":"2022-01-09T07:24:42.221232Z","shell.execute_reply":"2022-01-09T07:24:42.369413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_results(sample_idx):\n    rows = 64\n#     sample_idx = 1\n    sample_images, sample_labels = d_test_gen[sample_idx]\n\n    fig, axs = plt.subplots(nrows=rows, ncols=3, figsize=(6, 2*rows))\n    mean_psnr = 0.0\n    mean_ssim = 0.0\n    for i in range(rows):\n      impainted_image = d_model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n      axs[i][0].imshow(sample_labels[i])\n      axs[i][1].imshow(sample_images[i])\n      axs[i][2].imshow(impainted_image.reshape(impainted_image.shape[1:]))\n      mean_psnr += PSNR(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]))\n      mean_ssim += SSIM(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]), multichannel=True)\n\n\n    plt.show()\n    print(f\"Mean PSNR value = {mean_psnr/rows}\")\n    print(f\"Mean SSIM value = {mean_ssim/rows}\")\n    \nshow_results(2)","metadata":{"id":"xv7Ee_kcFW45","outputId":"07959ae3-f896-4a93-f779-0efd970b484e","execution":{"iopub.status.busy":"2022-01-09T07:24:42.373122Z","iopub.execute_input":"2022-01-09T07:24:42.373396Z","iopub.status.idle":"2022-01-09T07:25:06.560788Z","shell.execute_reply.started":"2022-01-09T07:24:42.373359Z","shell.execute_reply":"2022-01-09T07:25:06.560004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find(model, rows, sample_images, sample_labels):\n  mean_psnr = 0.0\n  mean_ssim = 0.0\n  for i in range(rows):\n    impainted_image = d_model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n    mean_psnr += PSNR(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]))\n    mean_ssim += SSIM(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]), multichannel=True)\n  \n  print(\"PSNR: \", mean_psnr/rows, \"\\nSSIM: \", mean_ssim/rows)\n  return (mean_psnr/rows, mean_ssim/rows)\n\nsample_idx = 1\nrows = 64\nn_iterations = 5\ntotal_psnr = 0.0\ntotal_ssim = 0.0;\nfor i in range(n_iterations):\n    sample_images, sample_labels = d_test_gen[sample_idx]\n    psnr, ssim = find(d_model, rows, sample_images, sample_labels)\n    total_psnr += psnr\n    total_ssim += ssim\n\nprint(f\"Mean of Mean PSNR value = {total_psnr/n_iterations}\")\nprint(f\"Mean of Mean SSIM value = {total_ssim/n_iterations}\")","metadata":{"id":"trGk9mD5csgM","outputId":"d4611f61-fdce-4c15-9328-3e0ea2ce64cc","execution":{"iopub.status.busy":"2022-01-09T07:25:06.562042Z","iopub.execute_input":"2022-01-09T07:25:06.562511Z","iopub.status.idle":"2022-01-09T07:25:37.311737Z","shell.execute_reply.started":"2022-01-09T07:25:06.562466Z","shell.execute_reply":"2022-01-09T07:25:37.310802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.clf()\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n                    y=d_history.history['dice_coef'],\n                    name='Train'))\nfig.add_trace(go.Scatter(\n                    y=d_history.history['val_dice_coef'],\n                    name='Valid'))\nfig.update_layout(height=500, \n                  width=700,\n                  title='Accuracy for image inpainting',\n                  xaxis_title='Epoch',\n                  yaxis_title='Accuracy')\nfig.show()","metadata":{"id":"NU9PKeRWFpH4","outputId":"a434aafe-ac6e-4a8d-d514-1b9013d937cf","execution":{"iopub.status.busy":"2022-01-09T07:25:37.313330Z","iopub.execute_input":"2022-01-09T07:25:37.313589Z","iopub.status.idle":"2022-01-09T07:25:37.367708Z","shell.execute_reply.started":"2022-01-09T07:25:37.313553Z","shell.execute_reply":"2022-01-09T07:25:37.367008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# img = cv2.imread('../input/quick-draw-irregular-mask-dataset/qd_imd/train/00000_train.png',cv2.IMREAD_GRAYSCALE)\n# img = cv2.resize(img, (256,256))\n# img.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:25:37.369129Z","iopub.execute_input":"2022-01-09T07:25:37.369429Z","iopub.status.idle":"2022-01-09T07:25:37.373488Z","shell.execute_reply.started":"2022-01-09T07:25:37.369373Z","shell.execute_reply":"2022-01-09T07:25:37.372313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(256):\n#     if(len(img[img==i])):\n#         print(i, len(img[img==i]))\n\n# thresh = 127\n# img_bw = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)[1]\n\n# for i in range(256):\n#     if(len(img_bw[img_bw==i])):\n#         print(i, len(img_bw[img_bw==i]))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:25:37.374673Z","iopub.execute_input":"2022-01-09T07:25:37.375149Z","iopub.status.idle":"2022-01-09T07:25:37.382753Z","shell.execute_reply.started":"2022-01-09T07:25:37.375112Z","shell.execute_reply":"2022-01-09T07:25:37.381982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_results(3)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:25:37.384666Z","iopub.execute_input":"2022-01-09T07:25:37.385231Z","iopub.status.idle":"2022-01-09T07:26:00.609065Z","shell.execute_reply.started":"2022-01-09T07:25:37.385183Z","shell.execute_reply":"2022-01-09T07:26:00.602701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_model.save(\"logcosh-rot-sat-30_70_downstream.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:26:00.610311Z","iopub.execute_input":"2022-01-09T07:26:00.610794Z","iopub.status.idle":"2022-01-09T07:26:03.231197Z","shell.execute_reply.started":"2022-01-09T07:26:00.610755Z","shell.execute_reply":"2022-01-09T07:26:03.230253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tensorflow.python.framework.ops.Tensor","metadata":{"execution":{"iopub.status.busy":"2022-01-09T07:26:03.232501Z","iopub.execute_input":"2022-01-09T07:26:03.232964Z","iopub.status.idle":"2022-01-09T07:26:03.249048Z","shell.execute_reply.started":"2022-01-09T07:26:03.232921Z","shell.execute_reply":"2022-01-09T07:26:03.248140Z"},"trusted":true},"execution_count":null,"outputs":[]}]}