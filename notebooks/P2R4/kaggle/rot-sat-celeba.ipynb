{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ! git clone https://github.com/seshuad/IMagenet\n# ! ls 'IMagenet/tiny-imagenet-200/'","metadata":{"id":"KJwsGk0LTpKw","outputId":"31a51b41-c4fe-454d-e9fd-a50a1e402933","execution":{"iopub.status.busy":"2021-12-12T04:51:33.04646Z","iopub.execute_input":"2021-12-12T04:51:33.047148Z","iopub.status.idle":"2021-12-12T04:51:33.06827Z","shell.execute_reply.started":"2021-12-12T04:51:33.047059Z","shell.execute_reply":"2021-12-12T04:51:33.067517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -U tensorflow-addons","metadata":{"id":"qDokTqy3vDZS","outputId":"2aefd72c-955c-4eed-a7aa-8b699ab95525","execution":{"iopub.status.busy":"2021-12-12T04:51:33.069928Z","iopub.execute_input":"2021-12-12T04:51:33.070286Z","iopub.status.idle":"2021-12-12T04:51:33.077349Z","shell.execute_reply.started":"2021-12-12T04:51:33.070234Z","shell.execute_reply":"2021-12-12T04:51:33.076524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport scipy.ndimage as nd\nimport scipy.misc\nimport cv2\nimport numpy as np\nimport os\nimport glob\nimport gc\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom PIL import Image, ImageEnhance\nfrom random import randint\nimport pandas as pd\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, concatenate\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Input\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n# from google.colab.patches import cv2_imshow\nimport plotly.graph_objects as go\n%matplotlib inline","metadata":{"id":"Odj0CnQKVU_s","execution":{"iopub.status.busy":"2021-12-12T04:51:33.079037Z","iopub.execute_input":"2021-12-12T04:51:33.079884Z","iopub.status.idle":"2021-12-12T04:51:39.1102Z","shell.execute_reply.started":"2021-12-12T04:51:33.079846Z","shell.execute_reply":"2021-12-12T04:51:39.109378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random as rn\nnp.random.seed(4321)\nrn.seed(4321)\ntf.random.set_seed(4321)","metadata":{"id":"rJtLvQpI-vZh","execution":{"iopub.status.busy":"2021-12-12T04:51:39.11151Z","iopub.execute_input":"2021-12-12T04:51:39.111773Z","iopub.status.idle":"2021-12-12T04:51:39.118869Z","shell.execute_reply.started":"2021-12-12T04:51:39.111736Z","shell.execute_reply":"2021-12-12T04:51:39.11762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract test and training data from Tiny ImageNet DataSet","metadata":{"id":"licJlNBnT-wO"}},{"cell_type":"code","source":"# cnt = 0\n# for file in os.listdir(path):\n#     print(file)\n#     cnt += 1\n#     if(cnt==5):\n#         break\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:51:39.120537Z","iopub.execute_input":"2021-12-12T04:51:39.120938Z","iopub.status.idle":"2021-12-12T04:51:39.133973Z","shell.execute_reply.started":"2021-12-12T04:51:39.120899Z","shell.execute_reply":"2021-12-12T04:51:39.133019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotate_image():\n  return randint(0,3)\n\ndef sharpen_image():\n  return randint(0,3)","metadata":{"id":"MHhiosHItf-K","execution":{"iopub.status.busy":"2021-12-12T04:51:39.135515Z","iopub.execute_input":"2021-12-12T04:51:39.135848Z","iopub.status.idle":"2021-12-12T04:51:39.144853Z","shell.execute_reply.started":"2021-12-12T04:51:39.135794Z","shell.execute_reply":"2021-12-12T04:51:39.144013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IM_WIDTH = IM_HEIGHT = 64\nTRAIN_TEST_SPLIT = 0.8\ndataset_dict = {\n    'rotation_id': {\n        0: '0', \n        1: '90', \n        2: '180', \n        3: '270', \n    },\n    'saturation_id': {\n        0: '0.0',\n        1: '0.25',\n        2: '0.75',\n        3: '1.0'\n    }\n}\ndataset_dict['rotation_alias'] = dict((r, i) for i, r in dataset_dict['rotation_id'].items())\ndataset_dict['saturation_alias'] = dict((s, i) for i, s in dataset_dict['saturation_id'].items())","metadata":{"id":"I5h8c_KkpgcH","execution":{"iopub.status.busy":"2021-12-12T04:51:39.146352Z","iopub.execute_input":"2021-12-12T04:51:39.146666Z","iopub.status.idle":"2021-12-12T04:51:39.156109Z","shell.execute_reply.started":"2021-12-12T04:51:39.146629Z","shell.execute_reply":"2021-12-12T04:51:39.155239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(dataset, ext='JPEG'):\n    def generate_rotate_sharp():\n      res_rot = rotate_image()\n      res_sharp = sharpen_image()\n      return [res_rot, res_sharp]\n    \n    records = []\n    for filename in os.listdir(dataset):\n        info = generate_rotate_sharp()\n        records.append(info+[dataset+'/'+filename])\n        \n    df = pd.DataFrame(records)\n    df.columns = ['rotation_id', 'saturation_id', 'image']\n    df = df.dropna()\n    \n    return df\n\npath = '../input/celebahq-resized-256x256/celeba_hq_256'\ndf = prepare_dataset(path)\ndf.head()","metadata":{"id":"LKgkvtNRB7DC","outputId":"cc242f8c-0d94-45e6-cabb-72344a2d2afc","execution":{"iopub.status.busy":"2021-12-12T04:51:39.157102Z","iopub.execute_input":"2021-12-12T04:51:39.15734Z","iopub.status.idle":"2021-12-12T04:51:40.180946Z","shell.execute_reply.started":"2021-12-12T04:51:39.1573Z","shell.execute_reply":"2021-12-12T04:51:40.180113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(pd_series, key):\n    labels = pd_series.value_counts().index.tolist()\n    counts = pd_series.value_counts().values.tolist()\n    labels = list(map(lambda id: dataset_dict[key][id], labels))\n    # self.df['rotation_id'] = self.df['rotation'].map(lambda rotation: dataset_dict['rotation_alias'][rotation])\n    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)\n    fig = go.Figure(data=[pie_plot])\n    fig.update_layout(title_text='Distribution for %s' % pd_series.name)\n    \n    fig.show()","metadata":{"id":"nGNx7r3kMsyF","execution":{"iopub.status.busy":"2021-12-12T04:51:40.182457Z","iopub.execute_input":"2021-12-12T04:51:40.182716Z","iopub.status.idle":"2021-12-12T04:51:40.190775Z","shell.execute_reply.started":"2021-12-12T04:51:40.182681Z","shell.execute_reply":"2021-12-12T04:51:40.189916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(df['rotation_id'], 'rotation_id')","metadata":{"id":"rprgp1hRMtTr","outputId":"9f521675-6822-48c0-ad21-cc26266fef28","execution":{"iopub.status.busy":"2021-12-12T04:51:40.194156Z","iopub.execute_input":"2021-12-12T04:51:40.19453Z","iopub.status.idle":"2021-12-12T04:51:40.306488Z","shell.execute_reply.started":"2021-12-12T04:51:40.194477Z","shell.execute_reply":"2021-12-12T04:51:40.305636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(df['saturation_id'], 'saturation_id')","metadata":{"id":"sH0HiLDmMxBI","outputId":"b5bb8709-4ebb-4cb9-8fe5-af93a2096ff2","execution":{"iopub.status.busy":"2021-12-12T04:51:40.307925Z","iopub.execute_input":"2021-12-12T04:51:40.30818Z","iopub.status.idle":"2021-12-12T04:51:40.320404Z","shell.execute_reply.started":"2021-12-12T04:51:40.308144Z","shell.execute_reply":"2021-12-12T04:51:40.31937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_random_crop(image, crop_height, crop_width):\n\n    max_x = image.shape[1] - crop_width\n    max_y = image.shape[0] - crop_height\n\n    x = np.random.randint(0, max_x)\n    y = np.random.randint(0, max_y)\n\n    crop = image[y: y + crop_height, x: x + crop_width]\n\n    return crop\n\n# example_image = np.random.randint(0, 256, (1024, 1024, 3))\n# random_crop = get_random_crop(example_image, 64, 64)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:51:40.322161Z","iopub.execute_input":"2021-12-12T04:51:40.322558Z","iopub.status.idle":"2021-12-12T04:51:40.330952Z","shell.execute_reply.started":"2021-12-12T04:51:40.322516Z","shell.execute_reply":"2021-12-12T04:51:40.330038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImgDataGenerator():\n    \"\"\"\n    Data generator for the Tiny imagenet dataset. This class should be used when training our Keras multi-output model.\n    \"\"\"\n    def __init__(self, df):\n        self.df = df\n        \n    def generate_split_indexes(self):\n        self.df = self.df.sample(frac=1).reset_index(drop=True)\n        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n        train_val_idx = self.df.tail(train_up_to)\n        test_idx = self.df.head(len(self.df) - train_up_to)\n        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n        train_val_idx = train_val_idx.sample(frac=1).reset_index(drop=True)\n        train_idx, valid_idx = train_val_idx.tail(train_up_to), train_val_idx.head(len(train_val_idx) - train_up_to)\n        \n        return train_idx, valid_idx, test_idx\n    \n    \n    def preprocess_image(self, sat: int, img_path):\n        \"\"\"\n        Used to perform some minor preprocessing on the image before inputting into the network.\n        \"\"\"\n        im_cv = cv2.imread(img_path)\n        im = cv2.cvtColor(im_cv, cv2.COLOR_BGR2RGB)\n        # Crop the image to 224 x 224\n        im = get_random_crop(im, 224, 224)\n        \n        # Continue preprocessing\n#         if rotate == 1:\n#           im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n#         elif rotate == 2:  \n#           im = cv2.rotate(im, cv2.ROTATE_180)\n#         elif rotate >= 3:\n#           im = cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n        enhancer = ImageEnhance.Color(Image.fromarray(im))\n        saturation = 0.\n        if sat == 1:\n          saturation = 0.25\n        elif sat == 2:  \n          saturation = 0.75\n        elif sat >= 3:\n          saturation = 1.\n        \n        out = np.array(enhancer.enhance(saturation))\n        out = out / 255.0\n        \n        return out\n        \n    def generate_images(self, image_idx, is_training, batch_size=16):\n        \"\"\"\n        Used to generate a batch with images when training/testing/validating our Keras model.\n        \"\"\"\n        \n        # arrays to store our batched data\n        images, sharps = [], []\n        while True:\n            for idx in range(len(image_idx)):\n                row = image_idx.iloc[idx]\n                \n#                 rotation = row['rotation_id']\n                saturation = row['saturation_id']\n                img_path = row['image']\n                \n                im = self.preprocess_image(saturation, img_path)\n                \n#                 cat_rot = to_categorical(rotation, 4)\n                cat_sharp = to_categorical(saturation, 4)\n#                 rotations.append(cat_rot)\n                sharps.append(cat_sharp)\n                # print(\"rotation = \",rotation,\"cat_rot = \",cat_rot)\n                # print(\"saturation = \",saturation,\"cat_sharp = \",cat_sharp)\n                images.append(im)\n                \n                # yielding condition\n                if len(images) >= batch_size:\n                    yield np.array(images), np.array(sharps)\n                    images, sharps = [], []\n                    \n            if not is_training:\n                break\n                \ndata_generator = ImgDataGenerator(df)\ntrain_idx, valid_idx, test_idx = data_generator.generate_split_indexes()","metadata":{"id":"UG-RQzjSksEN","execution":{"iopub.status.busy":"2021-12-12T04:51:40.332565Z","iopub.execute_input":"2021-12-12T04:51:40.33304Z","iopub.status.idle":"2021-12-12T04:51:40.359728Z","shell.execute_reply.started":"2021-12-12T04:51:40.332994Z","shell.execute_reply":"2021-12-12T04:51:40.358964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_idx.shape)\nprint(valid_idx.shape)\nprint(test_idx.shape)","metadata":{"id":"i9MeYjcUSDfQ","outputId":"49cc6047-37e4-4dac-ab54-1d224d827c6e","execution":{"iopub.status.busy":"2021-12-12T04:51:40.361037Z","iopub.execute_input":"2021-12-12T04:51:40.361767Z","iopub.status.idle":"2021-12-12T04:51:40.369526Z","shell.execute_reply.started":"2021-12-12T04:51:40.361726Z","shell.execute_reply":"2021-12-12T04:51:40.368786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(test_idx.head())\n# print(type(test_idx))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:51:40.371169Z","iopub.execute_input":"2021-12-12T04:51:40.371527Z","iopub.status.idle":"2021-12-12T04:51:40.37746Z","shell.execute_reply.started":"2021-12-12T04:51:40.371445Z","shell.execute_reply":"2021-12-12T04:51:40.376674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"execution":{"iopub.status.busy":"2021-12-12T04:51:40.378886Z","iopub.execute_input":"2021-12-12T04:51:40.379161Z","iopub.status.idle":"2021-12-12T04:51:40.39468Z","shell.execute_reply.started":"2021-12-12T04:51:40.379126Z","shell.execute_reply":"2021-12-12T04:51:40.393658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = 0\nif DEBUG:\n    fig = plt.figure(figsize=(20., 20.))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(4, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n    data_gen = data_generator.generate_images(test_idx, is_training=False, batch_size=8)\n  # images = data_gen[0]\n    for i,data in enumerate(data_gen):\n        images, outputs = data\n        print(len(images))\n#         for j, image in enumerate(images):\n#             image *= 255.0\n#             print(\"rotation \",outputs[0][j])\n#             print(\"saturation \",outputs[1][j])\n#             grid.imshow(image)\n            \n        for ax, im in zip(grid, images):\n            # Iterating over the grid returns the Axes.\n            ax.imshow(im)\n\n        plt.show()\n        break","metadata":{"id":"RnvdMQAXcKhD","execution":{"iopub.status.busy":"2021-12-12T04:51:40.395768Z","iopub.execute_input":"2021-12-12T04:51:40.396564Z","iopub.status.idle":"2021-12-12T04:51:40.405076Z","shell.execute_reply.started":"2021-12-12T04:51:40.396527Z","shell.execute_reply":"2021-12-12T04:51:40.404319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel = (3,3)\npool = (2,2)\nupstride = (2,2)\nactivation = 'relu'\nclass inpaintingModel:\n  def build_encoder(self, inputs):\n    # inputs = keras.layers.Input(input_size)\n    conv1, pool1 = self.__ConvBlock(64, kernel, pool, activation, 'same', inputs) \n    conv2, pool2 = self.__ConvBlock(128, kernel, pool, activation, 'same', pool1)\n    conv3, pool3 = self.__ConvBlock(256, kernel, pool, activation, 'same', pool2) \n    conv4, pool4 = self.__ConvBlock(512, kernel, pool, activation, 'same', pool3) \n    conv5, pool5 = self.__ConvBlock(1024, kernel, pool, activation, 'same', pool4)\n\n    return conv1, conv2, conv3, conv4, conv5, pool5\n\n  def build_decoder(self, conv1, conv2, conv3, conv4, conv5, pool_layer):\n    conv6, up7 = self.__UpConvBlock(2048, 1024, kernel, pool, upstride, activation, 'same', pool_layer, conv5)\n    conv7, up8 = self.__UpConvBlock(1024, 512, kernel, pool, upstride, activation, 'same', up7, conv4)\n    conv8, up9 = self.__UpConvBlock(512, 256, kernel, pool, upstride, activation, 'same', up8, conv3)\n    conv9, up10 = self.__UpConvBlock(256, 128, kernel, pool, upstride, activation, 'same', up9, conv2)\n    conv10, up11 = self.__UpConvBlock(128, 64, kernel, pool, upstride, activation, 'same', up10, conv1)\n\n    conv11 = self.__ConvBlock(32, kernel, pool, activation, 'same', up11, False)\n    \n    outputs = keras.layers.Conv2D(3, kernel, activation='sigmoid', padding='same')(conv11)\n\n    return outputs\n  '''\n  Build UNET like model for image inpaining task.\n  '''\n  def prepare_model(self, input_size=(224,224,3)):\n    inputs = keras.layers.Input(input_size)\n    conv1, conv2, conv3, conv4, conv5, pool_layer = self.build_encoder(inputs)\n    outputs = self.build_decoder(conv1, conv2, conv3, conv4, conv5, pool_layer)\n    # conv1, pool1 = self.__ConvBlock(64, kernel, pool, activation, 'same', inputs) \n    # conv2, pool2 = self.__ConvBlock(128, kernel, pool, activation, 'same', pool1)\n    # conv3, pool3 = self.__ConvBlock(256, kernel, pool, activation, 'same', pool2) \n    # conv4, pool4 = self.__ConvBlock(512, kernel, pool, activation, 'same', pool3) \n    # conv5, pool5 = self.__ConvBlock(1024, kernel, pool, activation, 'same', pool4)\n     \n\n    # conv6, up7 = self.__UpConvBlock(2048, 1024, kernel, pool, upstride, activation, 'same', pool5, conv5)\n    # conv7, up8 = self.__UpConvBlock(1024, 512, kernel, pool, upstride, activation, 'same', up7, conv4)\n    # conv8, up9 = self.__UpConvBlock(512, 256, kernel, pool, upstride, activation, 'same', up8, conv3)\n    # conv9, up10 = self.__UpConvBlock(256, 128, kernel, pool, upstride, activation, 'same', up9, conv2)\n    # conv10, up11 = self.__UpConvBlock(128, 64, kernel, pool, upstride, activation, 'same', up10, conv1)\n\n    # conv11 = self.__ConvBlock(64, kernel, pool, activation, 'same', up11, False)\n    \n    # outputs = keras.layers.Conv2D(3, kernel, activation='sigmoid', padding='same')(conv11)\n    # inpur\n    return keras.models.Model(inputs=[inputs], outputs=[outputs])  \n\n  def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n    if pool_layer:\n      pool = keras.layers.MaxPooling2D(pool_size)(conv)\n      return conv, pool\n    else:\n      return conv\n\n  def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n    up = keras.layers.Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)\n    up = keras.layers.concatenate([up, shared_layer], axis=3)\n\n    return conv, up","metadata":{"id":"mTjnopo0T56m","execution":{"iopub.status.busy":"2021-12-12T04:51:40.40643Z","iopub.execute_input":"2021-12-12T04:51:40.406698Z","iopub.status.idle":"2021-12-12T04:51:40.427981Z","shell.execute_reply.started":"2021-12-12T04:51:40.406662Z","shell.execute_reply":"2021-12-12T04:51:40.427057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class pretextModel:\n  def assemble_head_branch(self,  pool_layer, name):\n    x = Flatten()(pool_layer)\n    x = Dense(512)(x)\n    # x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n        \n    # x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    # x = Dense(2048, \n    #           kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n    #           bias_regularizer=tf.keras.regularizers.l2(1e-4),\n    #           activity_regularizer=tf.keras.regularizers.l2(1e-5))(x)\n    x = Dense(512)(x)\n    # x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    # x = BatchNormalization()(x)\n    x = Dropout(0.4)(x)\n    x = Dense(4)(x)\n    x = Activation(\"softmax\", name=name)(x)\n    return x\n\n  def assemble_pretext_model(self):\n    inputs = keras.layers.Input((224,224,3))\n    conv1, conv2, conv3, conv4, conv5, pool_layer = inpaintingModel().build_encoder(inputs) \n#     rotation_branch = self.assemble_head_branch(pool_layer, \"rotation_output\")\n    saturation_branch = self.assemble_head_branch(pool_layer, \"saturation_output\")\n    model = Model(inputs=inputs,\n                  outputs = [saturation_branch],\n                  name=\"pretext_net\")\n    return model","metadata":{"id":"2_Sw1JD55buR","execution":{"iopub.status.busy":"2021-12-12T04:51:40.43028Z","iopub.execute_input":"2021-12-12T04:51:40.43054Z","iopub.status.idle":"2021-12-12T04:51:40.442121Z","shell.execute_reply.started":"2021-12-12T04:51:40.430509Z","shell.execute_reply":"2021-12-12T04:51:40.441264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nkeras.backend.clear_session()","metadata":{"id":"nYur1hQvJQxl","execution":{"iopub.status.busy":"2021-12-12T04:51:40.444031Z","iopub.execute_input":"2021-12-12T04:51:40.444604Z","iopub.status.idle":"2021-12-12T04:51:40.468699Z","shell.execute_reply.started":"2021-12-12T04:51:40.444566Z","shell.execute_reply":"2021-12-12T04:51:40.467923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model = pretextModel().assemble_pretext_model()","metadata":{"id":"lYbHItKN4FwN","execution":{"iopub.status.busy":"2021-12-12T04:51:40.471027Z","iopub.execute_input":"2021-12-12T04:51:40.47128Z","iopub.status.idle":"2021-12-12T04:51:42.993261Z","shell.execute_reply.started":"2021-12-12T04:51:40.471248Z","shell.execute_reply":"2021-12-12T04:51:42.991469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(p_model, show_shapes=True, dpi=76, to_file='p_model_v1.png')","metadata":{"id":"in33Y6VFtvd8","outputId":"caf5df4d-3476-4856-e29e-196dba03a2ae","execution":{"iopub.status.busy":"2021-12-12T04:51:42.994653Z","iopub.execute_input":"2021-12-12T04:51:42.994904Z","iopub.status.idle":"2021-12-12T04:51:43.940869Z","shell.execute_reply.started":"2021-12-12T04:51:42.994868Z","shell.execute_reply":"2021-12-12T04:51:43.940093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model.summary()","metadata":{"id":"xqSMYuKnQuQW","outputId":"676139fd-a1a8-422c-d823-12e5d865d539","scrolled":true,"execution":{"iopub.status.busy":"2021-12-12T04:51:43.942334Z","iopub.execute_input":"2021-12-12T04:51:43.942651Z","iopub.status.idle":"2021-12-12T04:51:43.962962Z","shell.execute_reply.started":"2021-12-12T04:51:43.942607Z","shell.execute_reply":"2021-12-12T04:51:43.962092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\nepochs = 40\nopt = Adam(learning_rate=init_lr, amsgrad=False)\np_model.compile(optimizer=opt, \n              loss={\n#                   'rotation_output': 'categorical_crossentropy', \n                  'saturation_output': 'categorical_crossentropy'},\n#               loss_weights={\n#                   'rotation_output': 1.0, \n#                   'saturation_output': 0.0},\n              metrics={\n#                   'rotation_output': 'accuracy',\n                  'saturation_output': 'accuracy'})","metadata":{"id":"LyaXTzFgpWL7","execution":{"iopub.status.busy":"2021-12-12T04:51:43.964275Z","iopub.execute_input":"2021-12-12T04:51:43.964529Z","iopub.status.idle":"2021-12-12T04:51:43.984976Z","shell.execute_reply.started":"2021-12-12T04:51:43.964495Z","shell.execute_reply":"2021-12-12T04:51:43.984276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"./p_model_checkpoint\", monitor='val_loss')\nbatch_size = 64\ntrain_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\nvalid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=batch_size)\ncallbacks = [early_stopping, checkpoint]\nhistory = p_model.fit(train_gen,\n                    steps_per_epoch=len(train_idx)//batch_size,\n                    epochs=epochs,\n#                     callbacks=callbacks,\n                    # class_weight=dict(\n                    #     rotation_output = rots_dict,\n                    #     saturation_output = sharps_dict\n                    # ), \n                    # use_multiprocessing=True,\n                    validation_data=valid_gen,\n                    validation_steps=len(valid_idx)//batch_size)","metadata":{"id":"j0PS7XzZqF8Y","outputId":"c2933650-6311-4316-833d-3f6e58ad3a82","execution":{"iopub.status.busy":"2021-12-12T04:51:43.989574Z","iopub.execute_input":"2021-12-12T04:51:43.989782Z","iopub.status.idle":"2021-12-12T06:31:07.489702Z","shell.execute_reply.started":"2021-12-12T04:51:43.989757Z","shell.execute_reply":"2021-12-12T06:31:07.488908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history.history","metadata":{"execution":{"iopub.status.busy":"2021-12-12T06:40:07.835013Z","iopub.execute_input":"2021-12-12T06:40:07.83532Z","iopub.status.idle":"2021-12-12T06:40:07.843637Z","shell.execute_reply.started":"2021-12-12T06:40:07.835287Z","shell.execute_reply":"2021-12-12T06:40:07.842726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(metric):\n  plt.clf()\n  fig = go.Figure(layout_yaxis_range=[0,2])\n  fig.add_trace(go.Scatter(\n                      y=history.history[metric],\n                      name='Train'))\n  fig.add_trace(go.Scatter(\n                      y=history.history['val_'+metric],\n                      name='Valid'))\n  fig.update_layout(height=500, \n                    width=700,\n                    title=metric,\n                    xaxis_title='Epoch',\n                    yaxis_title='Accuracy/Loss')\n  fig.show()\n\nmetrics = ['accuracy', 'loss', 'loss']\nfor i in metrics:\n    plot_metric(i)","metadata":{"id":"hW_E0Uik9LLf","outputId":"3144d6cf-ff11-4592-a0dd-7b6ee2e79766","execution":{"iopub.status.busy":"2021-12-12T06:41:01.671969Z","iopub.execute_input":"2021-12-12T06:41:01.672242Z","iopub.status.idle":"2021-12-12T06:41:01.743038Z","shell.execute_reply.started":"2021-12-12T06:41:01.672194Z","shell.execute_reply":"2021-12-12T06:41:01.742208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model.save('sat.h5')\n# from tensorflow.keras.models import load_model\n# p_model = load_model('../input/pretexttaskmodel/rot-sat-30_70/rot-sat-30_70.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T06:40:45.794344Z","iopub.execute_input":"2021-12-12T06:40:45.795035Z","iopub.status.idle":"2021-12-12T06:40:46.803581Z","shell.execute_reply.started":"2021-12-12T06:40:45.794999Z","shell.execute_reply":"2021-12-12T06:40:46.802742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch_size = 64 # 256\ntest_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nsaturation_pred= p_model.predict(test_generator, \n                                                           steps=len(test_idx)//test_batch_size) # rotation_pred, ","metadata":{"id":"NzxfWygGC8tE","execution":{"iopub.status.busy":"2021-12-12T06:43:23.530576Z","iopub.execute_input":"2021-12-12T06:43:23.531128Z","iopub.status.idle":"2021-12-12T06:43:53.801173Z","shell.execute_reply.started":"2021-12-12T06:43:23.531086Z","shell.execute_reply":"2021-12-12T06:43:53.800406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nsamples = 0\nimages, saturation_true = [], [] # rotation_true, \nfor test_batch in test_generator:\n    image = test_batch[0]\n    labels = test_batch[1]\n    \n    images.extend(image)\n#     rotation_true.extend(labels[0])\n    saturation_true.extend(labels[1])\n    \n# rotation_true = np.array(rotation_true)\nsaturation_true = np.array(saturation_true)\nsaturation_true = saturation_true.argmax(axis=-1) # rotation_true, \nsaturation_pred = saturation_pred.argmax(axis=-1) # rotation_pred, \n","metadata":{"id":"E0IlUa85DFJH","execution":{"iopub.status.busy":"2021-12-12T06:45:29.077684Z","iopub.execute_input":"2021-12-12T06:45:29.078411Z","iopub.status.idle":"2021-12-12T06:45:54.206012Z","shell.execute_reply.started":"2021-12-12T06:45:29.07836Z","shell.execute_reply":"2021-12-12T06:45:54.205262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cr_rotation = classification_report(rotation_true, rotation_pred, target_names=dataset_dict['rotation_alias'].keys())\n# print(cr_rotation)","metadata":{"id":"nF35bZIODfm6","outputId":"f032439c-e339-44ef-8dd2-a752d9bb85eb","execution":{"iopub.status.busy":"2021-12-12T06:42:25.368744Z","iopub.status.idle":"2021-12-12T06:42:25.369381Z","shell.execute_reply.started":"2021-12-12T06:42:25.369104Z","shell.execute_reply":"2021-12-12T06:42:25.36913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr_saturation = classification_report(saturation_true, saturation_pred, target_names=dataset_dict['saturation_alias'].keys())\nprint(cr_saturation)","metadata":{"id":"jPGhCed7DrxU","outputId":"878634f0-cc36-4ae5-b52d-ace7c75d654e","execution":{"iopub.status.busy":"2021-12-12T06:46:35.668759Z","iopub.execute_input":"2021-12-12T06:46:35.669023Z","iopub.status.idle":"2021-12-12T06:46:35.706352Z","shell.execute_reply.started":"2021-12-12T06:46:35.668993Z","shell.execute_reply":"2021-12-12T06:46:35.704724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask_path = '../input/quick-draw-irregular-mask-dataset/qd_imd'\nmask_path = '../input/qd-imd-30-50/qd_imd'","metadata":{"execution":{"iopub.status.busy":"2021-12-12T06:48:07.413465Z","iopub.execute_input":"2021-12-12T06:48:07.41421Z","iopub.status.idle":"2021-12-12T06:48:07.419873Z","shell.execute_reply.started":"2021-12-12T06:48:07.41417Z","shell.execute_reply":"2021-12-12T06:48:07.418907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.\nclass createAugment(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, mask_path, is_training, batch_size=128, dim=(224, 224), n_channels=3, shuffle=True):\n        'Initialization'\n        self.batch_size = batch_size \n        self.df = df\n        self.mask_path = mask_path\n        self.is_training = is_training\n        self.dim = dim\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.df) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Generate data\n        return self.__data_generation(indexes)\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, idxs):\n        # X_batch is a matrix of masked images used as input\n        X_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Masked image\n        # y_batch is a matrix of original images used for computing error from reconstructed image\n        y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Original image\n\n        ## Iterate through random indexes\n        for i, idx in enumerate(idxs):\n            # image_copy = self.X[idx].copy()\n#             print(self.df.iloc[idx]['image'])\n            image_copy = cv2.imread(self.df.iloc[idx]['image'])\n            image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n            # Crop the image to 224 x 224\n            image_copy = get_random_crop(image_copy, 224, 224)\n\n            ## Get mask associated to that image\n            masked_image = self.__createMask(image_copy)\n\n            X_batch[i,] = masked_image/255\n            y_batch[i] = image_copy/255\n\n        return X_batch, y_batch\n\n    def __createMask(self, img):\n        directory = \"Unknown\"\n        mask_no = -1\n        if(self.is_training):\n            directory = 'train'\n            mask_no = np.random.randint(0,14991-1)\n        else:\n            directory = 'test'\n            mask_no = np.random.randint(0,3122-1)\n            \n        # Pad the mask_no\n        mask_no = str(mask_no).zfill(5)\n        \n        img_path = self.mask_path+'/'+ directory + '/' + mask_no + '_'+ directory + '.png'\n        mask = cv2.imread(img_path)\n#         mask = cv2.resize(mask, (256,256))\n#         mask = get_random_crop(mask, 224, 224)\n        \n#         thresh = 127\n#         mask = cv2.threshold(mask, thresh, 255, cv2.THRESH_BINARY)[1]\n#         print(type(img), type(mask))\n#         print(img.shape, mask.shape)\n        masked_image = cv2.bitwise_and(img, mask)\n\n        return masked_image","metadata":{"id":"uNUAcv_r_2Vj","execution":{"iopub.status.busy":"2021-12-12T06:48:13.491743Z","iopub.execute_input":"2021-12-12T06:48:13.492388Z","iopub.status.idle":"2021-12-12T06:48:13.521064Z","shell.execute_reply.started":"2021-12-12T06:48:13.492347Z","shell.execute_reply":"2021-12-12T06:48:13.520327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train, x_test, y_test = get_data(get_id_dictionary())","metadata":{"id":"YB-acxaFYCfH","outputId":"c97c563e-a226-4c1e-aed9-0a7eab1994bc","execution":{"iopub.status.busy":"2021-12-12T06:46:35.711467Z","iopub.status.idle":"2021-12-12T06:46:35.712075Z","shell.execute_reply.started":"2021-12-12T06:46:35.711838Z","shell.execute_reply":"2021-12-12T06:46:35.711869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Prepare training and testing mask-image pair generator\nd_train_gen = createAugment(train_idx, mask_path, is_training = 1, batch_size=64)\nd_test_gen = createAugment(test_idx, mask_path, is_training = 0, shuffle=False, batch_size=64)","metadata":{"id":"_FOZveBp_5Bn","execution":{"iopub.status.busy":"2021-12-12T06:48:16.287274Z","iopub.execute_input":"2021-12-12T06:48:16.287885Z","iopub.status.idle":"2021-12-12T06:48:16.292986Z","shell.execute_reply.started":"2021-12-12T06:48:16.287843Z","shell.execute_reply":"2021-12-12T06:48:16.292292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from mpl_toolkits.axes_grid1 import ImageGrid\n# type(d_train_gen)","metadata":{"id":"izuhVt9CZQsq","execution":{"iopub.status.busy":"2021-12-12T06:49:06.46666Z","iopub.execute_input":"2021-12-12T06:49:06.466975Z","iopub.status.idle":"2021-12-12T06:49:06.474398Z","shell.execute_reply.started":"2021-12-12T06:49:06.466938Z","shell.execute_reply":"2021-12-12T06:49:06.473505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Examples\nsample_idx = 90 ## Change this to see different batches\n\nsample_masks, sample_labels = d_train_gen[sample_idx]\nsample_images = [None]*(len(sample_masks)+len(sample_labels))\nsample_images[::2] = sample_labels\nsample_images[1::2] = sample_masks\n\nfig = plt.figure(figsize=(16., 8.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(4, 8),  # creates 2x2 grid of axes\n                 axes_pad=0.3,  # pad between axes in inch.\n                 )\n\nfor ax, image in zip(grid, sample_images):\n    ax.imshow(image)\n\nplt.show()","metadata":{"id":"5kK7AR03AEL4","outputId":"e96c8e49-f5c3-44df-aefd-a95beede04cb","execution":{"iopub.status.busy":"2021-12-12T06:48:18.260718Z","iopub.execute_input":"2021-12-12T06:48:18.260999Z","iopub.status.idle":"2021-12-12T06:48:23.865934Z","shell.execute_reply.started":"2021-12-12T06:48:18.260967Z","shell.execute_reply":"2021-12-12T06:48:23.865199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For more information into formulation: https://www.youtube.com/watch?v=AZr64OxshLo\n## Metric\nfrom sklearn.metrics import jaccard_score\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.backend.flatten(y_true)\n    y_pred_f = keras.backend.flatten(y_pred)\n    intersection = keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection) / (keras.backend.sum(y_true_f + y_pred_f))\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef ssim_loss(y_true, y_pred):\n    return 1 - SSIM(y_true, y_pred, multichannel=True)\n\ndef ssim_coef(y_true, y_pred):\n    return 1 - SSIM(y_true, y_pred, multichannel=True)\n\ndef SSIMLoss(y_true, y_pred):\n    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n\ndef custom_loss(y_true, y_pred):\n    alpha = 0.84\n#     loss_msssim = tf.image.ssim_multiscale(y_true, y_pred, 255)\n    loss_ssim = SSIMLoss(y_true, y_pred)\n#     jaccard_dist = jaccard_score(y_true.flatten(), y_pred.flatten())\n#     jaccard_dist = jaccard_distance(y_true, y_pred)\n    logcosh = tf.keras.losses.logcosh(y_true, y_pred)\n#     loss_mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n    return (1-alpha)*loss_ssim + alpha*logcosh","metadata":{"id":"SJdz5Sf1_jYU","execution":{"iopub.status.busy":"2021-12-12T06:48:23.867794Z","iopub.execute_input":"2021-12-12T06:48:23.868534Z","iopub.status.idle":"2021-12-12T06:48:23.880645Z","shell.execute_reply.started":"2021-12-12T06:48:23.868494Z","shell.execute_reply":"2021-12-12T06:48:23.879856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\nd_model = inpaintingModel().prepare_model()\ndepth = 16\ninit_lr = 1e-4\nopt = Adam(learning_rate=init_lr, amsgrad=False)\n  # d_model.layers[:depth]:\n  # print(i)\n  # layer.set_weights(p_model.layers)\n  # d_model.trainable_weights[i].assign(p_model.trainable_weights[i])\nfor i in range(depth):\n    d_model.layers[i].set_weights(p_model.layers[i].get_weights())\n    d_model.layers[i].trainable = False\nd_model.compile(optimizer=opt, loss= [custom_loss], metrics=[dice_coef], \n#                 run_eagerly = True\n               )\n\nkeras.utils.plot_model(d_model, show_shapes=True, dpi=76, to_file='d_model_v1.png')","metadata":{"id":"oiRBX-YI0fs9","outputId":"039e281d-2dfd-4ede-b183-2442af96d2d1","scrolled":true,"execution":{"iopub.status.busy":"2021-12-12T06:48:23.882053Z","iopub.execute_input":"2021-12-12T06:48:23.882943Z","iopub.status.idle":"2021-12-12T06:48:24.85891Z","shell.execute_reply.started":"2021-12-12T06:48:23.882897Z","shell.execute_reply":"2021-12-12T06:48:24.858078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_model.summary()","metadata":{"id":"Te29ATXfZzGA","outputId":"0e0758a9-91f2-47a6-e5b1-1bade3c6939e","scrolled":true,"execution":{"iopub.status.busy":"2021-12-12T06:46:37.015375Z","iopub.execute_input":"2021-12-12T06:46:37.016073Z","iopub.status.idle":"2021-12-12T06:46:37.020145Z","shell.execute_reply.started":"2021-12-12T06:46:37.01603Z","shell.execute_reply":"2021-12-12T06:46:37.019447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_model.layers[5].get_weights()","metadata":{"id":"wJwp4NDXZ-_E","execution":{"iopub.status.busy":"2021-12-12T06:46:37.022413Z","iopub.execute_input":"2021-12-12T06:46:37.023249Z","iopub.status.idle":"2021-12-12T06:46:37.03194Z","shell.execute_reply.started":"2021-12-12T06:46:37.023192Z","shell.execute_reply":"2021-12-12T06:46:37.030984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trying again\n## IT WORKS !!!","metadata":{"id":"dKYPHN--ezgP"}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"./d_model_checkpoint\", monitor='dice_coef')\nbatch_size = 64\n# train_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\n# valid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\ncallbacks = [early_stopping, checkpoint]\nd_history = d_model.fit(d_train_gen,\n                    # steps_per_epoch=len(d_train_gen)//batch_size,\n                    epochs=20,\n#                     callbacks=callbacks,\n                    # validation_split = 0.25\n                    validation_data=d_test_gen\n                    # validation_steps = len(d_test_gen)//batch_size\n                    )\n                    # class_weight=dict(\n                    #     rotation_output = rots_dict,\n                    #     saturation_output = sharps_dict\n                    # ), \n                    # use_multiprocessing=True,\n                    # validation_data=valid_gen,\n                    # validation_steps=len(valid_idx)//valid_batch_size)","metadata":{"id":"XCeHYnsOA5sW","outputId":"ef706b87-44bf-429f-b0dc-d1ca617b03be","execution":{"iopub.status.busy":"2021-12-12T06:49:19.434064Z","iopub.execute_input":"2021-12-12T06:49:19.434661Z","iopub.status.idle":"2021-12-12T08:42:08.220338Z","shell.execute_reply.started":"2021-12-12T06:49:19.434621Z","shell.execute_reply":"2021-12-12T08:42:08.219588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.metrics import structural_similarity as SSIM\nfrom skimage.metrics import peak_signal_noise_ratio as PSNR","metadata":{"id":"yBp4NwXNcnE9","execution":{"iopub.status.busy":"2021-12-12T08:42:08.22226Z","iopub.execute_input":"2021-12-12T08:42:08.222597Z","iopub.status.idle":"2021-12-12T08:42:08.366672Z","shell.execute_reply.started":"2021-12-12T08:42:08.222557Z","shell.execute_reply":"2021-12-12T08:42:08.365944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_results(sample_idx):\n    rows = 64\n#     sample_idx = 1\n    sample_images, sample_labels = d_test_gen[sample_idx]\n\n    fig, axs = plt.subplots(nrows=rows, ncols=3, figsize=(6, 2*rows))\n    mean_psnr = 0.0\n    mean_ssim = 0.0\n    for i in range(rows):\n      impainted_image = d_model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n      axs[i][0].imshow(sample_labels[i])\n      axs[i][1].imshow(sample_images[i])\n      axs[i][2].imshow(impainted_image.reshape(impainted_image.shape[1:]))\n      mean_psnr += PSNR(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]))\n      mean_ssim += SSIM(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]), multichannel=True)\n\n\n    plt.show()\n    print(f\"Mean PSNR value = {mean_psnr/rows}\")\n    print(f\"Mean SSIM value = {mean_ssim/rows}\")\n    \nshow_results(2)","metadata":{"id":"xv7Ee_kcFW45","outputId":"07959ae3-f896-4a93-f779-0efd970b484e","execution":{"iopub.status.busy":"2021-12-12T08:42:08.367857Z","iopub.execute_input":"2021-12-12T08:42:08.368182Z","iopub.status.idle":"2021-12-12T08:42:32.224916Z","shell.execute_reply.started":"2021-12-12T08:42:08.368145Z","shell.execute_reply":"2021-12-12T08:42:32.224117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find(model, rows, sample_images, sample_labels):\n  mean_psnr = 0.0\n  mean_ssim = 0.0\n  for i in range(rows):\n    impainted_image = d_model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n    mean_psnr += PSNR(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]))\n    mean_ssim += SSIM(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]), multichannel=True)\n  \n  print(\"PSNR: \", mean_psnr/rows, \"\\nSSIM: \", mean_ssim/rows)\n  return (mean_psnr/rows, mean_ssim/rows)\n\nsample_idx = 1\nrows = 64\nn_iterations = 5\ntotal_psnr = 0.0\ntotal_ssim = 0.0;\nfor i in range(n_iterations):\n    sample_images, sample_labels = d_test_gen[sample_idx]\n    psnr, ssim = find(d_model, rows, sample_images, sample_labels)\n    total_psnr += psnr\n    total_ssim += ssim\n\nprint(f\"Mean of Mean PSNR value = {total_psnr/n_iterations}\")\nprint(f\"Mean of Mean SSIM value = {total_ssim/n_iterations}\")","metadata":{"id":"trGk9mD5csgM","outputId":"d4611f61-fdce-4c15-9328-3e0ea2ce64cc","execution":{"iopub.status.busy":"2021-12-12T08:42:32.227201Z","iopub.execute_input":"2021-12-12T08:42:32.227641Z","iopub.status.idle":"2021-12-12T08:43:02.40336Z","shell.execute_reply.started":"2021-12-12T08:42:32.227604Z","shell.execute_reply":"2021-12-12T08:43:02.401523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.clf()\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n                    y=d_history.history['dice_coef'],\n                    name='Train'))\nfig.add_trace(go.Scatter(\n                    y=d_history.history['val_dice_coef'],\n                    name='Valid'))\nfig.update_layout(height=500, \n                  width=700,\n                  title='Accuracy for image inpainting',\n                  xaxis_title='Epoch',\n                  yaxis_title='Accuracy')\nfig.show()","metadata":{"id":"NU9PKeRWFpH4","outputId":"a434aafe-ac6e-4a8d-d514-1b9013d937cf","execution":{"iopub.status.busy":"2021-12-12T08:43:02.404695Z","iopub.execute_input":"2021-12-12T08:43:02.404954Z","iopub.status.idle":"2021-12-12T08:43:02.431624Z","shell.execute_reply.started":"2021-12-12T08:43:02.40492Z","shell.execute_reply":"2021-12-12T08:43:02.430904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# img = cv2.imread('../input/quick-draw-irregular-mask-dataset/qd_imd/train/00000_train.png',cv2.IMREAD_GRAYSCALE)\n# img = cv2.resize(img, (256,256))\n# img.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-12T06:46:37.082069Z","iopub.status.idle":"2021-12-12T06:46:37.082529Z","shell.execute_reply.started":"2021-12-12T06:46:37.082279Z","shell.execute_reply":"2021-12-12T06:46:37.082301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(256):\n#     if(len(img[img==i])):\n#         print(i, len(img[img==i]))\n\n# thresh = 127\n# img_bw = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)[1]\n\n# for i in range(256):\n#     if(len(img_bw[img_bw==i])):\n#         print(i, len(img_bw[img_bw==i]))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T06:46:37.083842Z","iopub.status.idle":"2021-12-12T06:46:37.084275Z","shell.execute_reply.started":"2021-12-12T06:46:37.084045Z","shell.execute_reply":"2021-12-12T06:46:37.084067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_results(3)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T08:43:02.432998Z","iopub.execute_input":"2021-12-12T08:43:02.433773Z","iopub.status.idle":"2021-12-12T08:43:24.6979Z","shell.execute_reply.started":"2021-12-12T08:43:02.433736Z","shell.execute_reply":"2021-12-12T08:43:24.697107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_model.save(\"rot-sat-100_0_downstream.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T08:43:24.699322Z","iopub.execute_input":"2021-12-12T08:43:24.699844Z","iopub.status.idle":"2021-12-12T08:43:29.474591Z","shell.execute_reply.started":"2021-12-12T08:43:24.699803Z","shell.execute_reply":"2021-12-12T08:43:29.473684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tensorflow.python.framework.ops.Tensor","metadata":{"execution":{"iopub.status.busy":"2021-12-12T06:46:37.089098Z","iopub.status.idle":"2021-12-12T06:46:37.090542Z","shell.execute_reply.started":"2021-12-12T06:46:37.090287Z","shell.execute_reply":"2021-12-12T06:46:37.090313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}