{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport scipy.ndimage as nd\nimport scipy.misc\nimport cv2\nimport numpy as np\nimport os\nimport glob\nimport gc\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom PIL import Image, ImageEnhance\nfrom random import randint\nimport pandas as pd\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, concatenate\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Input\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n# from google.colab.patches import cv2_imshow\nimport plotly.graph_objects as go\n%matplotlib inline","metadata":{"id":"Odj0CnQKVU_s","execution":{"iopub.status.busy":"2021-12-08T10:11:38.994348Z","iopub.execute_input":"2021-12-08T10:11:38.99471Z","iopub.status.idle":"2021-12-08T10:11:45.895134Z","shell.execute_reply.started":"2021-12-08T10:11:38.994641Z","shell.execute_reply":"2021-12-08T10:11:45.89407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random as rn\nnp.random.seed(4321)\nrn.seed(4321)\ntf.random.set_seed(4321)","metadata":{"id":"rJtLvQpI-vZh","execution":{"iopub.status.busy":"2021-12-08T10:11:45.897516Z","iopub.execute_input":"2021-12-08T10:11:45.897758Z","iopub.status.idle":"2021-12-08T10:11:45.902646Z","shell.execute_reply.started":"2021-12-08T10:11:45.897728Z","shell.execute_reply":"2021-12-08T10:11:45.901628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract test and training data from Tiny ImageNet DataSet","metadata":{"id":"licJlNBnT-wO"}},{"cell_type":"code","source":"def rotate_image():\n  return randint(0,3)\n\ndef sharpen_image():\n  return randint(0,3)\n\ndef saturate_image():\n  return randint(0,3)","metadata":{"id":"MHhiosHItf-K","execution":{"iopub.status.busy":"2021-12-08T10:11:45.933001Z","iopub.execute_input":"2021-12-08T10:11:45.933361Z","iopub.status.idle":"2021-12-08T10:11:45.94202Z","shell.execute_reply.started":"2021-12-08T10:11:45.933315Z","shell.execute_reply":"2021-12-08T10:11:45.940778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IM_WIDTH = IM_HEIGHT = 64\nTRAIN_TEST_SPLIT = 0.8\ndataset_dict = {\n    'rotation_id': {\n        0: '0', \n        1: '90', \n        2: '180', \n        3: '270', \n    },\n    'sharpness_id': {\n        0: '0.0',\n        1: '0.25',\n        2: '0.75',\n        3: '1.0'\n    },\n    'sat_id': {\n        0: '0.0',\n        1: '0.25',\n        2: '0.75',\n        3: '1.0'\n    }\n}\ndataset_dict['rotation_alias'] = dict((r, i) for i, r in dataset_dict['rotation_id'].items())\ndataset_dict['sharpness_alias'] = dict((s, i) for i, s in dataset_dict['sharpness_id'].items())\ndataset_dict['sat_alias'] = dict((s, i) for i, s in dataset_dict['sat_id'].items())","metadata":{"id":"I5h8c_KkpgcH","execution":{"iopub.status.busy":"2021-12-08T10:11:45.943843Z","iopub.execute_input":"2021-12-08T10:11:45.944838Z","iopub.status.idle":"2021-12-08T10:11:46.120599Z","shell.execute_reply.started":"2021-12-08T10:11:45.944665Z","shell.execute_reply":"2021-12-08T10:11:46.119489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(dataset, ext='JPEG'):\n    def generate_rotate_sharp():\n      res_rot = rotate_image()\n      res_sharp = sharpen_image()\n      res_sat = saturate_image()\n      return [res_rot, res_sharp, res_sat]\n    \n    records = []\n    for filename in os.listdir(dataset):\n        info = generate_rotate_sharp()\n        records.append(info+[dataset+'/'+filename])\n        \n    df = pd.DataFrame(records)\n    df.columns = ['rotation_id', 'sharpness_id', 'sat_id', 'image']\n    df = df.dropna()\n    \n    return df\n\npath = '../input/celebahq-resized-256x256/celeba_hq_256'\ndf = prepare_dataset(path)\ndf.head()","metadata":{"id":"LKgkvtNRB7DC","outputId":"cc242f8c-0d94-45e6-cabb-72344a2d2afc","execution":{"iopub.status.busy":"2021-12-08T10:11:46.125803Z","iopub.execute_input":"2021-12-08T10:11:46.126134Z","iopub.status.idle":"2021-12-08T10:11:47.743402Z","shell.execute_reply.started":"2021-12-08T10:11:46.126092Z","shell.execute_reply":"2021-12-08T10:11:47.742552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distribution(pd_series, key):\n    labels = pd_series.value_counts().index.tolist()\n    counts = pd_series.value_counts().values.tolist()\n    labels = list(map(lambda id: dataset_dict[key][id], labels))\n    # self.df['rotation_id'] = self.df['rotation'].map(lambda rotation: dataset_dict['rotation_alias'][rotation])\n    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)\n    fig = go.Figure(data=[pie_plot])\n    fig.update_layout(title_text='Distribution for %s' % pd_series.name)\n    \n    fig.show()","metadata":{"id":"nGNx7r3kMsyF","execution":{"iopub.status.busy":"2021-12-08T10:11:47.748014Z","iopub.execute_input":"2021-12-08T10:11:47.748235Z","iopub.status.idle":"2021-12-08T10:11:47.7563Z","shell.execute_reply.started":"2021-12-08T10:11:47.748205Z","shell.execute_reply":"2021-12-08T10:11:47.754898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(df['rotation_id'], 'rotation_id')","metadata":{"id":"rprgp1hRMtTr","outputId":"9f521675-6822-48c0-ad21-cc26266fef28","execution":{"iopub.status.busy":"2021-12-08T10:11:47.75802Z","iopub.execute_input":"2021-12-08T10:11:47.759283Z","iopub.status.idle":"2021-12-08T10:11:47.885458Z","shell.execute_reply.started":"2021-12-08T10:11:47.759025Z","shell.execute_reply":"2021-12-08T10:11:47.884422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_distribution(df['sharpness_id'], 'sharpness_id')","metadata":{"id":"sH0HiLDmMxBI","outputId":"b5bb8709-4ebb-4cb9-8fe5-af93a2096ff2","execution":{"iopub.status.busy":"2021-12-08T10:11:47.887288Z","iopub.execute_input":"2021-12-08T10:11:47.887818Z","iopub.status.idle":"2021-12-08T10:11:47.904427Z","shell.execute_reply.started":"2021-12-08T10:11:47.887773Z","shell.execute_reply":"2021-12-08T10:11:47.903196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_random_crop(image, crop_height, crop_width):\n\n    max_x = image.shape[1] - crop_width\n    max_y = image.shape[0] - crop_height\n\n    x = np.random.randint(0, max_x)\n    y = np.random.randint(0, max_y)\n\n    crop = image[y: y + crop_height, x: x + crop_width]\n\n    return crop\n","metadata":{"execution":{"iopub.status.busy":"2021-12-08T10:11:47.906146Z","iopub.execute_input":"2021-12-08T10:11:47.906574Z","iopub.status.idle":"2021-12-08T10:11:47.915258Z","shell.execute_reply.started":"2021-12-08T10:11:47.906517Z","shell.execute_reply":"2021-12-08T10:11:47.913819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImgDataGenerator():\n    \"\"\"\n    Data generator for the Tiny imagenet dataset. This class should be used when training our Keras multi-output model.\n    \"\"\"\n    def __init__(self, df):\n        self.df = df\n        \n    def generate_split_indexes(self):\n        self.df = self.df.sample(frac=1).reset_index(drop=True)\n        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\n        train_val_idx = self.df.tail(train_up_to)\n        test_idx = self.df.head(len(self.df) - train_up_to)\n        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\n        train_val_idx = train_val_idx.sample(frac=1).reset_index(drop=True)\n        train_idx, valid_idx = train_val_idx.tail(train_up_to), train_val_idx.head(len(train_val_idx) - train_up_to)\n        \n        return train_idx, valid_idx, test_idx\n    \n    \n    def preprocess_image(self, rotate: int, sharpen: int, sat: int, img_path):\n        \"\"\"\n        Used to perform some minor preprocessing on the image before inputting into the network.\n        \"\"\"\n        im_cv = cv2.imread(img_path)\n        im = cv2.cvtColor(im_cv, cv2.COLOR_BGR2RGB)\n        # Crop the image to 224 x 224\n        im = get_random_crop(im, 224, 224)\n        \n        # Continue preprocessing\n        if rotate == 1:\n          im = cv2.rotate(im, cv2.ROTATE_90_CLOCKWISE)\n        elif rotate == 2:  \n          im = cv2.rotate(im, cv2.ROTATE_180)\n        elif rotate >= 3:\n          im = cv2.rotate(im, cv2.ROTATE_90_COUNTERCLOCKWISE)\n\n        enhancer = ImageEnhance.Sharpness(Image.fromarray(im))\n        sharpness = 0.\n        if sharpen == 1:\n          sharpness = 0.25\n\n        elif sharpen == 2:  \n          sharpness = 0.75\n\n        elif sharpen >= 3:\n          sharpness = 1.\n\n        \n        out = np.array(enhancer.enhance(sharpness))\n\n        enhancer = ImageEnhance.Color(Image.fromarray(out))\n        if sat == 0:\n          sat = 0.0\n        elif sat == 1:\n          sat = 0.25\n        elif sat == 2:  \n          sat = 0.75\n        elif sat >= 3:\n          sat = 1.0\n        \n        out2 = np.array(enhancer.enhance(sat))\n        out2 = out2 / 255.0\n        \n        return out2\n        \n    def generate_images(self, image_idx, is_training, batch_size=16):\n        \"\"\"\n        Used to generate a batch with images when training/testing/validating our Keras model.\n        \"\"\"\n        \n        # arrays to store our batched data\n        images, rotations, sharps, sats = [], [], [], []\n        while True:\n            for idx in range(len(image_idx)):\n                row = image_idx.iloc[idx]\n                \n                rotation = row['rotation_id']\n                sharpness = row['sharpness_id']\n                sat = row['sat_id']\n                img_path = row['image']\n                \n                im = self.preprocess_image(rotation, sharpness, sat, img_path)\n                \n                cat_rot = to_categorical(rotation, 4)\n                cat_sharp = to_categorical(sharpness, 4)\n                cat_sat = to_categorical(sat,4)\n                rotations.append(cat_rot)\n                sharps.append(cat_sharp)\n                sats.append(cat_sat)\n\n                images.append(im)\n                \n                # yielding condition\n                if len(images) >= batch_size:\n                    yield np.array(images), [np.array(rotations), np.array(sharps), np.array(sats)]\n                    images, rotations, sharps, sats = [], [], [], []\n                    \n            if not is_training:\n                break\n                \ndata_generator = ImgDataGenerator(df)\ntrain_idx, valid_idx, test_idx = data_generator.generate_split_indexes()","metadata":{"id":"UG-RQzjSksEN","execution":{"iopub.status.busy":"2021-12-08T10:11:47.917595Z","iopub.execute_input":"2021-12-08T10:11:47.918164Z","iopub.status.idle":"2021-12-08T10:11:47.955239Z","shell.execute_reply.started":"2021-12-08T10:11:47.918118Z","shell.execute_reply":"2021-12-08T10:11:47.954262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_idx.shape)\nprint(valid_idx.shape)\nprint(test_idx.shape)","metadata":{"id":"i9MeYjcUSDfQ","outputId":"49cc6047-37e4-4dac-ab54-1d224d827c6e","execution":{"iopub.status.busy":"2021-12-08T10:11:47.95706Z","iopub.execute_input":"2021-12-08T10:11:47.957348Z","iopub.status.idle":"2021-12-08T10:11:47.964766Z","shell.execute_reply.started":"2021-12-08T10:11:47.957309Z","shell.execute_reply":"2021-12-08T10:11:47.963442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"execution":{"iopub.status.busy":"2021-12-08T10:11:47.976379Z","iopub.execute_input":"2021-12-08T10:11:47.977253Z","iopub.status.idle":"2021-12-08T10:11:47.99379Z","shell.execute_reply.started":"2021-12-08T10:11:47.977208Z","shell.execute_reply":"2021-12-08T10:11:47.992657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel = (3,3)\npool = (2,2)\nupstride = (2,2)\nactivation = 'relu'\nclass inpaintingModel:\n  def build_encoder(self, inputs):\n    # inputs = keras.layers.Input(input_size)\n    conv1, pool1 = self.__ConvBlock(64, kernel, pool, activation, 'same', inputs) \n    conv2, pool2 = self.__ConvBlock(128, kernel, pool, activation, 'same', pool1)\n    conv3, pool3 = self.__ConvBlock(256, kernel, pool, activation, 'same', pool2) \n    conv4, pool4 = self.__ConvBlock(512, kernel, pool, activation, 'same', pool3) \n    conv5, pool5 = self.__ConvBlock(1024, kernel, pool, activation, 'same', pool4)\n\n    return conv1, conv2, conv3, conv4, conv5, pool5\n\n  def build_decoder(self, conv1, conv2, conv3, conv4, conv5, pool_layer):\n    conv6, up7 = self.__UpConvBlock(2048, 1024, kernel, pool, upstride, activation, 'same', pool_layer, conv5)\n    conv7, up8 = self.__UpConvBlock(1024, 512, kernel, pool, upstride, activation, 'same', up7, conv4)\n    conv8, up9 = self.__UpConvBlock(512, 256, kernel, pool, upstride, activation, 'same', up8, conv3)\n    conv9, up10 = self.__UpConvBlock(256, 128, kernel, pool, upstride, activation, 'same', up9, conv2)\n    conv10, up11 = self.__UpConvBlock(128, 64, kernel, pool, upstride, activation, 'same', up10, conv1)\n\n    conv11 = self.__ConvBlock(32, kernel, pool, activation, 'same', up11, False)\n    \n    outputs = keras.layers.Conv2D(3, kernel, activation='sigmoid', padding='same')(conv11)\n\n    return outputs\n  '''\n  Build UNET like model for image inpaining task.\n  '''\n  def prepare_model(self, input_size=(224,224,3)):\n    inputs = keras.layers.Input(input_size)\n    conv1, conv2, conv3, conv4, conv5, pool_layer = self.build_encoder(inputs)\n    outputs = self.build_decoder(conv1, conv2, conv3, conv4, conv5, pool_layer)\n\n    return keras.models.Model(inputs=[inputs], outputs=[outputs])  \n\n  def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n    if pool_layer:\n      pool = keras.layers.MaxPooling2D(pool_size)(conv)\n      return conv, pool\n    else:\n      return conv\n\n  def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n    up = keras.layers.Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)\n    up = keras.layers.concatenate([up, shared_layer], axis=3)\n\n    return conv, up","metadata":{"id":"mTjnopo0T56m","execution":{"iopub.status.busy":"2021-12-08T10:11:48.007358Z","iopub.execute_input":"2021-12-08T10:11:48.007831Z","iopub.status.idle":"2021-12-08T10:11:48.034839Z","shell.execute_reply.started":"2021-12-08T10:11:48.00778Z","shell.execute_reply":"2021-12-08T10:11:48.033715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class pretextModel:\n  def assemble_head_branch(self,  pool_layer, name):\n    x = Flatten()(pool_layer)\n    x = Dense(512)(x)\n    x = Activation(\"relu\")(x)\n        \n    x = Dropout(0.4)(x)\n\n    x = Dense(512)(x)\n\n    x = Activation(\"relu\")(x)\n\n    x = Dropout(0.4)(x)\n    x = Dense(4)(x)\n    x = Activation(\"softmax\", name=name)(x)\n    return x\n\n  def assemble_pretext_model(self):\n    inputs = keras.layers.Input((224,224,3))\n    conv1, conv2, conv3, conv4, conv5, pool_layer = inpaintingModel().build_encoder(inputs) \n    rotation_branch = self.assemble_head_branch(pool_layer, \"rotation_output\")\n    sharpness_branch = self.assemble_head_branch(pool_layer, \"sharpness_output\")\n    sats_branch = self.assemble_head_branch(pool_layer, \"sats_output\")\n    model = Model(inputs=inputs,\n                  outputs = [rotation_branch, sharpness_branch, sats_branch],\n                  name=\"pretext_net\")\n    return model","metadata":{"id":"2_Sw1JD55buR","execution":{"iopub.status.busy":"2021-12-08T10:11:48.038088Z","iopub.execute_input":"2021-12-08T10:11:48.039264Z","iopub.status.idle":"2021-12-08T10:11:48.051423Z","shell.execute_reply.started":"2021-12-08T10:11:48.039217Z","shell.execute_reply":"2021-12-08T10:11:48.050233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nkeras.backend.clear_session()","metadata":{"id":"nYur1hQvJQxl","execution":{"iopub.status.busy":"2021-12-08T10:11:48.053529Z","iopub.execute_input":"2021-12-08T10:11:48.053908Z","iopub.status.idle":"2021-12-08T10:11:48.080067Z","shell.execute_reply.started":"2021-12-08T10:11:48.053852Z","shell.execute_reply":"2021-12-08T10:11:48.07919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model = pretextModel().assemble_pretext_model()","metadata":{"id":"lYbHItKN4FwN","execution":{"iopub.status.busy":"2021-12-08T10:11:48.08154Z","iopub.execute_input":"2021-12-08T10:11:48.081851Z","iopub.status.idle":"2021-12-08T10:11:51.185664Z","shell.execute_reply.started":"2021-12-08T10:11:48.081811Z","shell.execute_reply":"2021-12-08T10:11:51.184732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(p_model, show_shapes=True, dpi=76, to_file='p_model_v1.png')","metadata":{"id":"in33Y6VFtvd8","outputId":"caf5df4d-3476-4856-e29e-196dba03a2ae","scrolled":true,"execution":{"iopub.status.busy":"2021-12-08T10:11:51.188281Z","iopub.execute_input":"2021-12-08T10:11:51.188997Z","iopub.status.idle":"2021-12-08T10:11:52.370407Z","shell.execute_reply.started":"2021-12-08T10:11:51.188951Z","shell.execute_reply":"2021-12-08T10:11:52.367822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model.summary()","metadata":{"id":"xqSMYuKnQuQW","outputId":"676139fd-a1a8-422c-d823-12e5d865d539","scrolled":true,"execution":{"iopub.status.busy":"2021-12-08T10:11:52.371972Z","iopub.execute_input":"2021-12-08T10:11:52.37232Z","iopub.status.idle":"2021-12-08T10:11:52.409289Z","shell.execute_reply.started":"2021-12-08T10:11:52.372233Z","shell.execute_reply":"2021-12-08T10:11:52.408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"init_lr = 1e-4\nepochs = 40\nopt = Adam(learning_rate=init_lr, amsgrad=False)\np_model.compile(optimizer=opt, \n              loss={\n                  'rotation_output': 'categorical_crossentropy', \n                  'sharpness_output': 'categorical_crossentropy',\n                  'sats_output': 'categorical_crossentropy',\n              },\n              \n              loss_weights={\n                  'rotation_output': 0.3, \n                  'sharpness_output': 0.4,\n                  'sats_output': 0.3\n              },\n              metrics={\n                  'rotation_output': 'accuracy',\n                  'sharpness_output': 'accuracy',\n                  'sats_output': 'accuracy',\n              })","metadata":{"id":"LyaXTzFgpWL7","execution":{"iopub.status.busy":"2021-12-08T10:11:52.410894Z","iopub.execute_input":"2021-12-08T10:11:52.411263Z","iopub.status.idle":"2021-12-08T10:11:52.436433Z","shell.execute_reply.started":"2021-12-08T10:11:52.411222Z","shell.execute_reply":"2021-12-08T10:11:52.435509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"./p_model_checkpoint\", monitor='val_loss')\nbatch_size = 64\ntrain_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\nvalid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=batch_size)\ncallbacks = [early_stopping, checkpoint]\nhistory = p_model.fit(train_gen,\n                    steps_per_epoch=len(train_idx)//batch_size,\n                    epochs=epochs,\n                    validation_data=valid_gen,\n                    validation_steps=len(valid_idx)//batch_size)","metadata":{"id":"j0PS7XzZqF8Y","outputId":"c2933650-6311-4316-833d-3f6e58ad3a82","execution":{"iopub.status.busy":"2021-12-08T10:11:52.438132Z","iopub.execute_input":"2021-12-08T10:11:52.438793Z","iopub.status.idle":"2021-12-08T12:28:17.814189Z","shell.execute_reply.started":"2021-12-08T10:11:52.438748Z","shell.execute_reply":"2021-12-08T12:28:17.813026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metric(metric):\n  plt.clf()\n  fig = go.Figure(layout_yaxis_range=[0,2])\n  fig.add_trace(go.Scatter(\n                      y=history.history[metric],\n                      name='Train'))\n  fig.add_trace(go.Scatter(\n                      y=history.history['val_'+metric],\n                      name='Valid'))\n  fig.update_layout(height=500, \n                    width=700,\n                    title=metric,\n                    xaxis_title='Epoch',\n                    yaxis_title='Accuracy/Loss')\n  fig.show()\n\nmetrics = ['rotation_output_accuracy', 'rotation_output_loss', 'sharpness_output_accuracy', 'sharpness_output_loss', 'sats_output_accuracy', 'sats_output_loss', 'loss']\nfor i in metrics:\n    plot_metric(i)","metadata":{"id":"hW_E0Uik9LLf","outputId":"3144d6cf-ff11-4592-a0dd-7b6ee2e79766","execution":{"iopub.status.busy":"2021-12-08T12:28:17.834368Z","iopub.execute_input":"2021-12-08T12:28:17.835142Z","iopub.status.idle":"2021-12-08T12:28:17.972367Z","shell.execute_reply.started":"2021-12-08T12:28:17.835088Z","shell.execute_reply":"2021-12-08T12:28:17.971176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_model.save('rot-sha-10_90.h5')\n# from tensorflow.keras.models import load_model\n# p_model = load_model('../input/pretexttaskmodel/rot-sha-30_70/rot-sha-30_70.h5')","metadata":{"execution":{"iopub.status.busy":"2021-12-08T12:28:17.974407Z","iopub.execute_input":"2021-12-08T12:28:17.974768Z","iopub.status.idle":"2021-12-08T12:28:20.653187Z","shell.execute_reply.started":"2021-12-08T12:28:17.974723Z","shell.execute_reply":"2021-12-08T12:28:20.651984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_batch_size = 64 # 256\ntest_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nrotation_pred, sharpness_pred, sats_pred = p_model.predict(test_generator, \n                                                           steps=len(test_idx)//test_batch_size)","metadata":{"id":"NzxfWygGC8tE","execution":{"iopub.status.busy":"2021-12-08T12:28:20.654636Z","iopub.execute_input":"2021-12-08T12:28:20.655726Z","iopub.status.idle":"2021-12-08T12:29:52.039819Z","shell.execute_reply.started":"2021-12-08T12:28:20.655692Z","shell.execute_reply":"2021-12-08T12:29:52.038755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = data_generator.generate_images(test_idx, is_training=False, batch_size=test_batch_size)\nsamples = 0\nimages, rotation_true, sharpness_true, sats_true = [], [], [], []\nfor test_batch in test_generator:\n    image = test_batch[0]\n    labels = test_batch[1]\n    \n    images.extend(image)\n    rotation_true.extend(labels[0])\n    sharpness_true.extend(labels[1])\n    sats_true.extend(labels[2])\n    \nrotation_true = np.array(rotation_true)\nsharpness_true = np.array(sharpness_true)\nsats_true = np.array(sats_true)\nrotation_true, sharpness_true, sats_true = rotation_true.argmax(axis=-1), sharpness_true.argmax(axis=-1), sats_true.argmax(axis=-1)\nrotation_pred, sharpness_pred, sats_pred = rotation_pred.argmax(axis=-1), sharpness_pred.argmax(axis=-1), sats_pred.argmax(axis=-1)\n","metadata":{"id":"E0IlUa85DFJH","execution":{"iopub.status.busy":"2021-12-08T12:29:52.041416Z","iopub.execute_input":"2021-12-08T12:29:52.04178Z","iopub.status.idle":"2021-12-08T12:30:30.837442Z","shell.execute_reply.started":"2021-12-08T12:29:52.041694Z","shell.execute_reply":"2021-12-08T12:30:30.836452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr_rotation = classification_report(rotation_true, rotation_pred, target_names=dataset_dict['rotation_alias'].keys())\nprint(cr_rotation)","metadata":{"id":"nF35bZIODfm6","outputId":"f032439c-e339-44ef-8dd2-a752d9bb85eb","execution":{"iopub.status.busy":"2021-12-08T12:30:30.839259Z","iopub.execute_input":"2021-12-08T12:30:30.839607Z","iopub.status.idle":"2021-12-08T12:30:30.877691Z","shell.execute_reply.started":"2021-12-08T12:30:30.839549Z","shell.execute_reply":"2021-12-08T12:30:30.875867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr_sharpness = classification_report(sharpness_true, sharpness_pred, target_names=dataset_dict['sharpness_alias'].keys())\nprint(cr_sharpness)","metadata":{"id":"jPGhCed7DrxU","outputId":"878634f0-cc36-4ae5-b52d-ace7c75d654e","execution":{"iopub.status.busy":"2021-12-08T12:30:30.882234Z","iopub.execute_input":"2021-12-08T12:30:30.882652Z","iopub.status.idle":"2021-12-08T12:30:30.912708Z","shell.execute_reply.started":"2021-12-08T12:30:30.882604Z","shell.execute_reply":"2021-12-08T12:30:30.911736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr_sats = classification_report(sats_true, sats_pred, target_names=dataset_dict['sat_alias'].keys())\nprint(cr_sats)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T12:30:30.91611Z","iopub.execute_input":"2021-12-08T12:30:30.916796Z","iopub.status.idle":"2021-12-08T12:30:30.955353Z","shell.execute_reply.started":"2021-12-08T12:30:30.91674Z","shell.execute_reply":"2021-12-08T12:30:30.953736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmask_path = '../input/qd-30-50/qd_imd'","metadata":{"execution":{"iopub.status.busy":"2021-12-08T12:30:30.957512Z","iopub.execute_input":"2021-12-08T12:30:30.958254Z","iopub.status.idle":"2021-12-08T12:30:30.965821Z","shell.execute_reply.started":"2021-12-08T12:30:30.958209Z","shell.execute_reply":"2021-12-08T12:30:30.962209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.\nclass createAugment(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, mask_path, is_training, batch_size=128, dim=(224, 224), n_channels=3, shuffle=True):\n        'Initialization'\n        self.batch_size = batch_size \n        self.df = df\n        self.mask_path = mask_path\n        self.is_training = is_training\n        self.dim = dim\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.df) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Generate data\n        return self.__data_generation(indexes)\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, idxs):\n        # X_batch is a matrix of masked images used as input\n        X_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Masked image\n        # y_batch is a matrix of original images used for computing error from reconstructed image\n        y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Original image\n\n        ## Iterate through random indexes\n        for i, idx in enumerate(idxs):\n\n            image_copy = cv2.imread(self.df.iloc[idx]['image'])\n            image_copy = cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB)\n            # Crop the image to 224 x 224\n            image_copy = get_random_crop(image_copy, 224, 224)\n\n            ## Get mask associated to that image\n            masked_image = self.__createMask(image_copy)\n\n            X_batch[i,] = masked_image/255\n            y_batch[i] = image_copy/255\n\n        return X_batch, y_batch\n\n    def __createMask(self, img):\n        directory = \"Unknown\"\n        mask_no = -1\n        if(self.is_training):\n            directory = 'train'\n            mask_no = np.random.randint(0,14991-1)\n        else:\n            directory = 'test'\n            mask_no = np.random.randint(0,3122-1)\n            \n        # Pad the mask_no\n        mask_no = str(mask_no).zfill(5)\n        \n        img_path = self.mask_path+'/'+ directory + '/' + mask_no + '_'+ directory + '.png'\n        mask = cv2.imread(img_path)\n\n        \n        masked_image = cv2.bitwise_and(img, mask)\n\n        return masked_image","metadata":{"id":"uNUAcv_r_2Vj","execution":{"iopub.status.busy":"2021-12-08T12:30:30.968334Z","iopub.execute_input":"2021-12-08T12:30:30.969015Z","iopub.status.idle":"2021-12-08T12:30:31.004596Z","shell.execute_reply.started":"2021-12-08T12:30:30.968954Z","shell.execute_reply":"2021-12-08T12:30:31.003427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Prepare training and testing mask-image pair generator\nd_train_gen = createAugment(train_idx, mask_path, is_training = 1, batch_size=64)\nd_test_gen = createAugment(test_idx, mask_path, is_training = 0, shuffle=False, batch_size=64)","metadata":{"id":"_FOZveBp_5Bn","execution":{"iopub.status.busy":"2021-12-08T12:30:31.016307Z","iopub.execute_input":"2021-12-08T12:30:31.017342Z","iopub.status.idle":"2021-12-08T12:30:31.031411Z","shell.execute_reply.started":"2021-12-08T12:30:31.017296Z","shell.execute_reply":"2021-12-08T12:30:31.03008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid","metadata":{"id":"izuhVt9CZQsq","execution":{"iopub.status.busy":"2021-12-08T12:30:31.033271Z","iopub.execute_input":"2021-12-08T12:30:31.033979Z","iopub.status.idle":"2021-12-08T12:30:31.050381Z","shell.execute_reply.started":"2021-12-08T12:30:31.033916Z","shell.execute_reply":"2021-12-08T12:30:31.048749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Examples\nsample_idx = 90 ## Change this to see different batches\n\nsample_masks, sample_labels = d_train_gen[sample_idx]\nsample_images = [None]*(len(sample_masks)+len(sample_labels))\nsample_images[::2] = sample_labels\nsample_images[1::2] = sample_masks\n\nfig = plt.figure(figsize=(16., 8.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(4, 8),  # creates 2x2 grid of axes\n                 axes_pad=0.3,  # pad between axes in inch.\n                 )\n\nfor ax, image in zip(grid, sample_images):\n    ax.imshow(image)\n\nplt.show()","metadata":{"id":"5kK7AR03AEL4","outputId":"e96c8e49-f5c3-44df-aefd-a95beede04cb","execution":{"iopub.status.busy":"2021-12-08T12:30:31.05729Z","iopub.execute_input":"2021-12-08T12:30:31.05754Z","iopub.status.idle":"2021-12-08T12:30:37.997304Z","shell.execute_reply.started":"2021-12-08T12:30:31.057511Z","shell.execute_reply":"2021-12-08T12:30:37.996128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## For more information into formulation: https://www.youtube.com/watch?v=AZr64OxshLo\n## Metric\nfrom sklearn.metrics import jaccard_score\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = keras.backend.flatten(y_true)\n    y_pred_f = keras.backend.flatten(y_pred)\n    intersection = keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection) / (keras.backend.sum(y_true_f + y_pred_f))\n\ndef dice_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef ssim_loss(y_true, y_pred):\n    return 1 - SSIM(y_true, y_pred, multichannel=True)\n\ndef ssim_coef(y_true, y_pred):\n    return 1 - SSIM(y_true, y_pred, multichannel=True)\n\ndef SSIMLoss(y_true, y_pred):\n  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\ndef custom_loss(y_true, y_pred):\n    alpha = 0.84\n    loss_ssim = SSIMLoss(y_true, y_pred)\n    \n#     jaccard_dist = jaccard_score(y_true.flatten(), y_pred.flatten())\n#     jaccard_dist = jaccard_distance(y_true, y_pred)\n    logcosh = tf.keras.losses.logcosh(y_true, y_pred)\n#     loss_mae = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n    return (1-alpha)*loss_ssim + alpha*logcosh","metadata":{"id":"SJdz5Sf1_jYU","execution":{"iopub.status.busy":"2021-12-08T12:30:37.999255Z","iopub.execute_input":"2021-12-08T12:30:38.000277Z","iopub.status.idle":"2021-12-08T12:30:38.014266Z","shell.execute_reply.started":"2021-12-08T12:30:38.000233Z","shell.execute_reply":"2021-12-08T12:30:38.013235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\nd_model = inpaintingModel().prepare_model()\ndepth = 16\ninit_lr = 1e-4\nopt = Adam(learning_rate=init_lr, amsgrad=False)\n  # d_model.layers[:depth]:\n  # print(i)\n  # layer.set_weights(p_model.layers)\n  # d_model.trainable_weights[i].assign(p_model.trainable_weights[i])\nfor i in range(depth):\n    d_model.layers[i].set_weights(p_model.layers[i].get_weights())\n    d_model.layers[i].trainable = False\nd_model.compile(optimizer=opt, loss= [custom_loss], metrics=[dice_coef], \n#                 run_eagerly = True\n               )\n\nkeras.utils.plot_model(d_model, show_shapes=True, dpi=76, to_file='d_model_v1.png')","metadata":{"id":"oiRBX-YI0fs9","outputId":"039e281d-2dfd-4ede-b183-2442af96d2d1","scrolled":true,"execution":{"iopub.status.busy":"2021-12-08T12:30:38.016019Z","iopub.execute_input":"2021-12-08T12:30:38.016375Z","iopub.status.idle":"2021-12-08T12:30:39.490833Z","shell.execute_reply.started":"2021-12-08T12:30:38.01633Z","shell.execute_reply":"2021-12-08T12:30:39.489707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_model.summary()","metadata":{"id":"Te29ATXfZzGA","outputId":"0e0758a9-91f2-47a6-e5b1-1bade3c6939e","scrolled":true,"execution":{"iopub.status.busy":"2021-12-08T12:30:39.493255Z","iopub.execute_input":"2021-12-08T12:30:39.49454Z","iopub.status.idle":"2021-12-08T12:30:39.500061Z","shell.execute_reply.started":"2021-12-08T12:30:39.494497Z","shell.execute_reply":"2021-12-08T12:30:39.499124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# d_model.layers[5].get_weights()","metadata":{"id":"wJwp4NDXZ-_E","execution":{"iopub.status.busy":"2021-12-08T12:30:39.502152Z","iopub.execute_input":"2021-12-08T12:30:39.503037Z","iopub.status.idle":"2021-12-08T12:30:39.512273Z","shell.execute_reply.started":"2021-12-08T12:30:39.502991Z","shell.execute_reply":"2021-12-08T12:30:39.51136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\ncheckpoint = ModelCheckpoint(\"./d_model_checkpoint\", monitor='dice_coef')\nbatch_size = 64\n\ncallbacks = [early_stopping, checkpoint]\nd_history = d_model.fit(d_train_gen,\n                    epochs=20,\n\n                    validation_data=d_test_gen\n                    )\n","metadata":{"id":"XCeHYnsOA5sW","outputId":"ef706b87-44bf-429f-b0dc-d1ca617b03be","execution":{"iopub.status.busy":"2021-12-08T12:30:39.514482Z","iopub.execute_input":"2021-12-08T12:30:39.51508Z","iopub.status.idle":"2021-12-08T14:23:51.631Z","shell.execute_reply.started":"2021-12-08T12:30:39.515019Z","shell.execute_reply":"2021-12-08T14:23:51.62987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from skimage.metrics import structural_similarity as SSIM\nfrom skimage.metrics import peak_signal_noise_ratio as PSNR","metadata":{"id":"yBp4NwXNcnE9","execution":{"iopub.status.busy":"2021-12-08T14:23:51.632824Z","iopub.execute_input":"2021-12-08T14:23:51.633455Z","iopub.status.idle":"2021-12-08T14:23:51.815181Z","shell.execute_reply.started":"2021-12-08T14:23:51.633368Z","shell.execute_reply":"2021-12-08T14:23:51.814115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_results(sample_idx):\n    rows = 64\n#     sample_idx = 1\n    sample_images, sample_labels = d_test_gen[sample_idx]\n\n    fig, axs = plt.subplots(nrows=rows, ncols=3, figsize=(6, 2*rows))\n    mean_psnr = 0.0\n    mean_ssim = 0.0\n    for i in range(rows):\n      impainted_image = d_model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n      axs[i][0].imshow(sample_labels[i])\n      axs[i][1].imshow(sample_images[i])\n      axs[i][2].imshow(impainted_image.reshape(impainted_image.shape[1:]))\n      mean_psnr += PSNR(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]))\n      mean_ssim += SSIM(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]), multichannel=True)\n\n\n    plt.show()\n    print(f\"Mean PSNR value = {mean_psnr/rows}\")\n    print(f\"Mean SSIM value = {mean_ssim/rows}\")\n    \nshow_results(2)","metadata":{"id":"xv7Ee_kcFW45","outputId":"07959ae3-f896-4a93-f779-0efd970b484e","execution":{"iopub.status.busy":"2021-12-08T14:23:51.817081Z","iopub.execute_input":"2021-12-08T14:23:51.817389Z","iopub.status.idle":"2021-12-08T14:24:22.996889Z","shell.execute_reply.started":"2021-12-08T14:23:51.817347Z","shell.execute_reply":"2021-12-08T14:24:22.995658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find(model, rows, sample_images, sample_labels):\n  mean_psnr = 0.0\n  mean_ssim = 0.0\n  for i in range(rows):\n    impainted_image = d_model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n    mean_psnr += PSNR(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]))\n    mean_ssim += SSIM(sample_labels[i],impainted_image.reshape(impainted_image.shape[1:]), multichannel=True)\n  \n  print(\"PSNR: \", mean_psnr/rows, \"\\nSSIM: \", mean_ssim/rows)\n  return (mean_psnr/rows, mean_ssim/rows)\n\nsample_idx = 1\nrows = 64\nn_iterations = 5\ntotal_psnr = 0.0\ntotal_ssim = 0.0;\nfor i in range(n_iterations):\n    sample_images, sample_labels = d_test_gen[sample_idx]\n    psnr, ssim = find(d_model, rows, sample_images, sample_labels)\n    total_psnr += psnr\n    total_ssim += ssim\n\nprint(f\"Mean of Mean PSNR value = {total_psnr/n_iterations}\")\nprint(f\"Mean of Mean SSIM value = {total_ssim/n_iterations}\")","metadata":{"id":"trGk9mD5csgM","outputId":"d4611f61-fdce-4c15-9328-3e0ea2ce64cc","execution":{"iopub.status.busy":"2021-12-08T14:24:22.999339Z","iopub.execute_input":"2021-12-08T14:24:22.999898Z","iopub.status.idle":"2021-12-08T14:24:58.317482Z","shell.execute_reply.started":"2021-12-08T14:24:22.999855Z","shell.execute_reply":"2021-12-08T14:24:58.315133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.clf()\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n                    y=d_history.history['dice_coef'],\n                    name='Train'))\nfig.add_trace(go.Scatter(\n                    y=d_history.history['val_dice_coef'],\n                    name='Valid'))\nfig.update_layout(height=500, \n                  width=700,\n                  title='Accuracy for image inpainting',\n                  xaxis_title='Epoch',\n                  yaxis_title='Accuracy')\nfig.show()","metadata":{"id":"NU9PKeRWFpH4","outputId":"a434aafe-ac6e-4a8d-d514-1b9013d937cf","execution":{"iopub.status.busy":"2021-12-08T14:24:58.319257Z","iopub.execute_input":"2021-12-08T14:24:58.319557Z","iopub.status.idle":"2021-12-08T14:24:58.352351Z","shell.execute_reply.started":"2021-12-08T14:24:58.319513Z","shell.execute_reply":"2021-12-08T14:24:58.35124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import cv2\n# img = cv2.imread('../input/quick-draw-irregular-mask-dataset/qd_imd/train/00000_train.png',cv2.IMREAD_GRAYSCALE)\n# img = cv2.resize(img, (256,256))\n# img.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:24:58.354046Z","iopub.execute_input":"2021-12-08T14:24:58.354499Z","iopub.status.idle":"2021-12-08T14:24:58.36034Z","shell.execute_reply.started":"2021-12-08T14:24:58.35445Z","shell.execute_reply":"2021-12-08T14:24:58.358684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(256):\n#     if(len(img[img==i])):\n#         print(i, len(img[img==i]))\n\n# thresh = 127\n# img_bw = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)[1]\n\n# for i in range(256):\n#     if(len(img_bw[img_bw==i])):\n#         print(i, len(img_bw[img_bw==i]))","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:24:58.36273Z","iopub.execute_input":"2021-12-08T14:24:58.363109Z","iopub.status.idle":"2021-12-08T14:24:58.372793Z","shell.execute_reply.started":"2021-12-08T14:24:58.363061Z","shell.execute_reply":"2021-12-08T14:24:58.371538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_results(3)","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:24:58.374548Z","iopub.execute_input":"2021-12-08T14:24:58.374978Z","iopub.status.idle":"2021-12-08T14:25:27.797483Z","shell.execute_reply.started":"2021-12-08T14:24:58.374932Z","shell.execute_reply":"2021-12-08T14:25:27.796556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_model.save(\"rot-sha-sat-10_90_downstream.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:25:27.799353Z","iopub.execute_input":"2021-12-08T14:25:27.799846Z","iopub.status.idle":"2021-12-08T14:25:35.962367Z","shell.execute_reply.started":"2021-12-08T14:25:27.799803Z","shell.execute_reply":"2021-12-08T14:25:35.961137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tensorflow.python.framework.ops.Tensor","metadata":{"execution":{"iopub.status.busy":"2021-12-08T14:25:35.965061Z","iopub.execute_input":"2021-12-08T14:25:35.965616Z","iopub.status.idle":"2021-12-08T14:25:35.970742Z","shell.execute_reply.started":"2021-12-08T14:25:35.965566Z","shell.execute_reply":"2021-12-08T14:25:35.969375Z"},"trusted":true},"execution_count":null,"outputs":[]}]}